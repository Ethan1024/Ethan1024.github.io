{"meta":{"title":"Ethan的个人博客","subtitle":"","description":"","author":"Ethan","url":"http://example.com","root":"/"},"pages":[{"title":"about","date":"2021-10-21T04:43:07.000Z","updated":"2022-05-05T01:56:48.103Z","comments":false,"path":"about/index.html","permalink":"http://example.com/about/index.html","excerpt":"","text":"ayo,what's up! 🐱name: ethan🐲address: shaanxi xi'an 🐺email: higher1212@163.com"}],"posts":[{"title":"Pytorch 中 “forward”使用","slug":"Pytorch中的“forward”","date":"2022-04-13T13:30:50.000Z","updated":"2022-07-06T09:31:23.639Z","comments":true,"path":"2022/04/13/Pytorch中的“forward”/","link":"","permalink":"http://example.com/2022/04/13/Pytorch%E4%B8%AD%E7%9A%84%E2%80%9Cforward%E2%80%9D/","excerpt":"","text":"Pytorch 中 “forward”使用数据进入网络模型的主要处理流程：数据集输入 -&gt; 网络前向传播 -&gt; 损失loss计算 -&gt; 反向传播计算梯度 -&gt; 根据梯度自动调参 **call函数:**可将类的实例对象变为可调用对象 123456class Rapper(): def __call__(self,name,AKA): print(&quot;我是实例对象781号Rapper:&#123;&#125;,AKA:&#123;&#125;&quot; .format (name, AKA)) num_781_Rapper = Rapper()num_781_Rapper(&quot;周延&quot;,&quot;gai&quot;) 12output: 我是实例对象781号Rapper:周延,AKA:gai call函数调用forward，当把定义的网络模型model当作函数调用的时候就自动调用定义的网络模型的forward方法。 1234567891011121314151617class Rapper: def __call__(self, Name): search = self.forward(Name) return search def forward(self, name): print(&#x27;信息查询函数 函数被调用了&#x27;) if name == &#x27;gai&#x27;: print(&#x27;姓名：&#123;&#125; 来自: &#123;&#125;&#x27;.format(name, &quot;重庆&quot;)) else: print(&quot;系统未录入此人信息&quot;) return namerapper = Rapper()about = rapper(&#x27;gai&#x27;)print(&quot;目标人物：&quot;, about) 1234output: 信息查询函数 函数被调用了 姓名：gai 来自: 重庆 目标人物： gai 参考：pytorch 中的 forward 的使用与解释 PyTorch之前向传播函数forward Pytorch 中的 forward理解","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"练习","slug":"深度学习/练习","permalink":"http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%BB%83%E4%B9%A0/"}],"tags":[{"name":"前向传播函数","slug":"前向传播函数","permalink":"http://example.com/tags/%E5%89%8D%E5%90%91%E4%BC%A0%E6%92%AD%E5%87%BD%E6%95%B0/"},{"name":"forward","slug":"forward","permalink":"http://example.com/tags/forward/"}],"author":"Ethan"},{"title":"python中self的使用","slug":"python中self的使用","date":"2022-04-10T01:56:50.000Z","updated":"2022-07-05T09:54:41.994Z","comments":true,"path":"2022/04/10/python中self的使用/","link":"","permalink":"http://example.com/2022/04/10/python%E4%B8%ADself%E7%9A%84%E4%BD%BF%E7%94%A8/","excerpt":"","text":"python中self的使用self的用法牵扯到类（class）和实例（instance）的概念，实例需要通过类来创建。 class被创建为模板，根据类创建的实例会包含类的所有属性。 由于类起到模板的作用，因此，可以在创建实例的时候，把我们认为必须绑定的属性强制填写进去。这里就用到Python当中的一个内置方法__init__方法，例如在Student类时，把name、score等属性绑上去。 例子: 类和方法 12345678class Rapper(object): def __init__(self, name, AKA): self.name = name self.AKA = AKARapper = Rapper(&quot;周延&quot;,&quot;Gai&quot;)print(Rapper.name)print(Rapper.AKA) 123output： 周延 gai 类内部定义访问数据的函数 123456789class Rapper(object): #类 def __init__(self, name, AKA): #方法,作用是封装数据，便于调用。init 中第一个参数 self 表示实例本体，self代表类的实例，而非类 self.name = name self.AKA = AKA def relationship(self): print (&quot;Name: %s\\nAKA: %s&quot; % (self.name, self.AKA))Rapper = Rapper(&quot;zhouyan&quot;,&quot;gai&quot;)Rapper.relationship() 123output: Name: zhouyan AKA: gai 类内部定义访问和修改私有变量的函数 12345678910111213141516171819class Rapper(object): #类 def __init__(self, name, AKA): #方法 self.__name = name self.__AKA = AKA def relationship(self): print (&quot;姓名: %s\\nAKA: %s&quot; % (self.__name, self.__AKA)) #私有变量可以不被外部轻易访问 def get_name(self): #需要访问和修改的情况下定义以下两个函数 return self.__name def get_AKA(self): return self.__AKA #外部函数修改私有变量 def set_AKA(self, AKA): self.__AKA = AKARapper = Rapper(&quot;周延&quot;,&quot;gai&quot;)Rapper.relationship()print(&#x27;-----------------------------&#x27;)Rapper.set_AKA(&#x27;金牌小密探&#x27;)Rapper.relationship() 123456output: 姓名: 周延 AKA: gai ----------------------------- 姓名: 周延 AKA: 金牌小密探 参考：Python中self用法详解_CLHugh的博客-CSDN博客_python中的self","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"练习","slug":"深度学习/练习","permalink":"http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%BB%83%E4%B9%A0/"}],"tags":[{"name":"实例","slug":"实例","permalink":"http://example.com/tags/%E5%AE%9E%E4%BE%8B/"},{"name":"类","slug":"类","permalink":"http://example.com/tags/%E7%B1%BB/"}],"author":"Ethan"},{"title":"python中的\" self \"","slug":"python中的self ","date":"2022-04-10T01:56:50.000Z","updated":"2022-07-05T09:58:03.574Z","comments":true,"path":"2022/04/10/python中的self /","link":"","permalink":"http://example.com/2022/04/10/python%E4%B8%AD%E7%9A%84self%20/","excerpt":"","text":"python中的” self “self的用法牵扯到类（class）和实例（instance）的概念，实例需要通过类来创建。 class被创建为模板，根据类创建的实例会包含类的所有属性。 由于类起到模板的作用，因此，可以在创建实例的时候，把我们认为必须绑定的属性强制填写进去。这里就用到Python当中的一个内置方法__init__方法，例如在Student类时，把name、score等属性绑上去。 例子: 类和方法 12345678class Rapper(object): def __init__(self, name, AKA): self.name = name self.AKA = AKARapper = Rapper(&quot;周延&quot;,&quot;Gai&quot;)print(Rapper.name)print(Rapper.AKA) 123output： 周延 gai 类内部定义访问数据的函数 123456789class Rapper(object): #类 def __init__(self, name, AKA): #方法,作用是封装数据，便于调用。init 中第一个参数 self 表示实例本体，self代表类的实例，而非类 self.name = name self.AKA = AKA def relationship(self): print (&quot;Name: %s\\nAKA: %s&quot; % (self.name, self.AKA))Rapper = Rapper(&quot;zhouyan&quot;,&quot;gai&quot;)Rapper.relationship() 123output: Name: zhouyan AKA: gai 类内部定义访问和修改私有变量的函数 12345678910111213141516171819class Rapper(object): #类 def __init__(self, name, AKA): #方法 self.__name = name self.__AKA = AKA def relationship(self): print (&quot;姓名: %s\\nAKA: %s&quot; % (self.__name, self.__AKA)) #私有变量可以不被外部轻易访问 def get_name(self): #需要访问和修改的情况下定义以下两个函数 return self.__name def get_AKA(self): return self.__AKA #外部函数修改私有变量 def set_AKA(self, AKA): self.__AKA = AKARapper = Rapper(&quot;周延&quot;,&quot;gai&quot;)Rapper.relationship()print(&#x27;-----------------------------&#x27;)Rapper.set_AKA(&#x27;金牌小密探&#x27;)Rapper.relationship() 123456output: 姓名: 周延 AKA: gai ----------------------------- 姓名: 周延 AKA: 金牌小密探 参考：Python中self用法详解_CLHugh的博客-CSDN博客_python中的self","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"练习","slug":"深度学习/练习","permalink":"http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%BB%83%E4%B9%A0/"}],"tags":[{"name":"实例","slug":"实例","permalink":"http://example.com/tags/%E5%AE%9E%E4%BE%8B/"},{"name":"类","slug":"类","permalink":"http://example.com/tags/%E7%B1%BB/"}],"author":"Ethan"},{"title":"“炼丹”之数据组成","slug":"“炼丹”的数据组成","date":"2022-04-07T03:26:50.000Z","updated":"2022-07-05T09:37:10.998Z","comments":true,"path":"2022/04/07/“炼丹”的数据组成/","link":"","permalink":"http://example.com/2022/04/07/%E2%80%9C%E7%82%BC%E4%B8%B9%E2%80%9D%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%84%E6%88%90/","excerpt":"","text":"“炼丹”之数据组成待机器进行学习的标注数据被送入火炉前会被分为：训练集、验证集、测试集。三者发挥自己的作用对网络模型进行构建、筛选调整以及评估。主干网络的骨架在训练阶段利用训练集的特征拟合了模型的血和肉，训练的过程并不会用到测试集和验证集。验证集主要用来评估迭代训练时当前模型泛化能力（准确率，召回率等），以决定是否停止继续训练。在神经网络中， 我们用验证数据集去寻找最优的网络深度，或者决定反向传播算法的停止点或者在神经网络中选择隐藏层神经元的数量； 类别 验证集 测试集 作用 纯粹用于调超参数 纯粹为了加试以验证泛化性能 使用次数 多次使用，以不断调参 仅仅一次使用 用于训练 否 否 两者的缺陷：模型在一次次重新手动调参并继续训练后所逼近的验证集，可能只代表一部分非训练集，导致最终训练好的模型泛化性能不够 测试集为了具有泛化代表性，往往数据量比较大，测试一轮要很久，所以往往只取测试集的其中一小部分作为训练过程中的验证集 互相转化：验证集具有足够泛化性（一般来说，如果验证集足够大到包括大部分非训练集时，也等于具有足够泛化性了）验证集具有足够泛化性时，测试集就没有存在的必要 训练集和测试集的划分12345678910111213141516171819202122print(&quot;Generate txt in ImageSets.&quot;)xmlfilepath = os.path.join(VOCdevkit_path, &#x27;VOC2007/Annotations&#x27;)saveBasePath = os.path.join(VOCdevkit_path, &#x27;VOC2007/ImageSets/Main&#x27;)temp_xml = os.listdir(xmlfilepath) #传入xml文件的路径,返回该目录下的所有xml文件名total_xml = []for xml in temp_xml: if xml.endswith(&quot;.xml&quot;): total_xml.append(xml) #添加每个xml文件num = len(total_xml) list = range(num) #返回xml文件列表tv = int(num*trainval_percent) tr = int(tv*train_percent) trainval= random.sample(list,tv) train = random.sample(trainval,tr) print(&quot;train and val size&quot;,tv)print(&quot;train size&quot;,tr)ftrainval = open(os.path.join(saveBasePath,&#x27;trainval.txt&#x27;), &#x27;w&#x27;) ftest = open(os.path.join(saveBasePath,&#x27;test.txt&#x27;), &#x27;w&#x27;) ftrain = open(os.path.join(saveBasePath,&#x27;train.txt&#x27;), &#x27;w&#x27;) fval = open(os.path.join(saveBasePath,&#x27;val.txt&#x27;), &#x27;w&#x27;) range函数返回一个range类型的整数序列，一般用在循环结构中。 参数名称 说明 备注 start 计数起始位置 整数参数，可省略。省略时默认从0开始计数 stop 计数终点位置 不可省略的整数参数。计数迭代的序列中不包含stop step 步长 可省略的整数参数，默认时步长为1 12345678910111213141516for i in list: name=total_xml[i][:-4]+&#x27;\\n&#x27; if i in trainval: ftrainval.write(name) if i in train: ftrain.write(name) else: fval.write(name) else: ftest.write(name) ftrainval.close() ftrain.close() fval.close() ftest.close()print(&quot;Generate txt in ImageSets done.&quot;) 参考：训练集、验证集、测试集以及交验验证的理解 验证集和测试集有什么区别？ 深度学习: 验证集 &amp; 测试集 区别","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"炼丹笔记","slug":"深度学习/炼丹笔记","permalink":"http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%82%BC%E4%B8%B9%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"训练集","slug":"训练集","permalink":"http://example.com/tags/%E8%AE%AD%E7%BB%83%E9%9B%86/"},{"name":"测试集","slug":"测试集","permalink":"http://example.com/tags/%E6%B5%8B%E8%AF%95%E9%9B%86/"},{"name":"验证集","slug":"验证集","permalink":"http://example.com/tags/%E9%AA%8C%E8%AF%81%E9%9B%86/"}],"author":"Ethan"},{"title":"交叉熵损失函数🔋","slug":"损失函数｜交叉熵损失函数","date":"2022-03-20T08:03:50.000Z","updated":"2022-05-05T02:48:04.845Z","comments":true,"path":"2022/03/20/损失函数｜交叉熵损失函数/","link":"","permalink":"http://example.com/2022/03/20/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%EF%BD%9C%E4%BA%A4%E5%8F%89%E7%86%B5%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/","excerpt":"","text":"损失函数｜交叉熵损失函数⚠️ 真实面试题 假设我们有一个图像分类的任务，图片特征已经提取好，维度D，类别数N： 题目1 请用Pytorch/TF代码编写分类器：(1) 3层全连接；(2) 具有非线性变化；（3）具有过拟合处理题目2 这个任务，你会使用什么损失函数？题目3 交叉熵表达式？题目4 为什么使用交叉熵？能不能用MSE？题目5 如果让你选择提取图片特征的模型，你会选择什么模型？ *主成分分析法(PCA) 提取的是数据分布方差比较大的方向，隐藏层可以提取有预测能力的特征 *混沌度可以理解为不确定性，当然是越低越好。 *输入图片大小为200×200，依次经过一层卷积（kernel size 5×5，padding 1，stride 2），pooling（kernel size 3×3，padding 0，stride 1），又一层卷积（kernel size 3×3，padding 1，stride 1）之后，输出特征图大小为: ​ **97 ** 解答 卷积向下取整,池化向上取整 12345计算公式为：( input_size - kernel_size + 2*padding) / stride+1 = output_size)输出高度 = （输入高度 - Kernel高度 + 2 * padding）/ 步长stride + 1输出宽度 = （输入宽度 - Kernel宽度 + 2 * padding）/ 步长stride + 1","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"炼丹笔记","slug":"深度学习/炼丹笔记","permalink":"http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%82%BC%E4%B8%B9%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"卷积","slug":"卷积","permalink":"http://example.com/tags/%E5%8D%B7%E7%A7%AF/"},{"name":"池化","slug":"池化","permalink":"http://example.com/tags/%E6%B1%A0%E5%8C%96/"},{"name":"损失函数","slug":"损失函数","permalink":"http://example.com/tags/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/"}],"author":"Ethan"},{"title":"极本穷源：YOLO篇Ⅲ","slug":"极本穷源：YOLO篇Ⅲ","date":"2022-03-07T13:26:50.000Z","updated":"2022-03-07T05:28:17.578Z","comments":true,"path":"2022/03/07/极本穷源：YOLO篇Ⅲ/","link":"","permalink":"http://example.com/2022/03/07/%E6%9E%81%E6%9C%AC%E7%A9%B7%E6%BA%90%EF%BC%9AYOLO%E7%AF%87%E2%85%A2/","excerpt":"","text":"极本穷源：YOLO篇ⅢYOLOV4-tiny源码解读有了基本概念的理解，接着深入源码一步一步学习。在开始之前先做下回顾，小目标&amp;&amp;配置文件参数解读 小目标识别检测中”小目标”尺寸占原始图片的比例：ubuntu下安装个labelImg，查看下标注目标时的尺寸。labelImg图片标注工具安装 从 PyPI 获取，但只有 python3.0 或更高版本，这是现代Linux发行版（如Ubuntu和Fedora）上最简单的（单命令）安装方法。 123pip3 install labelImglabelImglabelImg [IMAGE_PATH] [PRE-DEFINED CLASS FILE] 经不完全统计。本次数据集目标尺寸大致如下： 大部分尺寸 最大 最小 肉眼看不见 目标尺寸 170x151 1200x2356 47x82 167x95 图片尺寸 5472x3648 5472x3648 5472x3648 5472x3648 yolov4-tiny.cfg配置文件解读训练开始之前根据自己的显卡性能调整btach以及subdivisions的大小，普遍以batch = 64,subdivisions = 16设置。显卡差点的subdivisions设置成64。 整个训练样本会被分成若干个batch，网络中每个batch积累64个样本后会进行一次正向传播（在训练的过程中将一次性加载64张图片进内存）。subdivisions表示每个batch会分16次完成前向传播，前向传播的循环过程中累加loss求平均，待64张图片都完成前向传播后，再一次性后传更新参数。 12345678910111213141516171819202122232425262728293031[net]# Testing # 图片测试#batch=1 #subdivisions=1# Training # 数据训练batch=64 #subdivisions=16 #width=416 #输入图像的宽height=416channels=3 #图像通道数，RGB三色图片 momentum=0.9 #动量系数decay=0.0005 #权重衰减正则项，防止过拟合#图像增强，通过旋转图片，改变饱和度等操作增加训练样本数angle=0 #角度saturation = 1.5 #饱和度exposure = 1.5 #曝光量hue=.1 #色调#学习率的调整learning_rate=0.00261 #学习率burn_in=1000 #应该是在1000轮后产生计算mapmax_batches = 3000 #训练论次policy=steps #调整学习率的policy，有如下policy：CONSTANT, STEP, EXP, POLY, STEPS, SIG, RANDOMsteps=1600000,1800000 #根据batch_num调整学习率scales=.1,.1 #学习率变化比例，累计相乘 convolutional在训练数据前要修改每个yolo下的classes类别数，以及每个yolo上的第一个filters卷积核个数（等于输出的特征图的维度）：filters=(classes + 5)x3。 q:公式中的5是怎么来的？ 这5个数分别包括：pc,bx, by, bh, bw。其中pc 为标志位，代表检测框中是否包含对象，框中包含任一目标对象 时pc = 1,反之只有背景没有目标时pc = 0。后面四个为bounding box的边界参数，分别是对象的中心位置x和y 坐标，对象的高和宽。参考博客理解，后面乘以3就很容易理解，rgb三个通道的意思吧，红绿蓝三个通道各卷 一次。 每个卷积层之后包含一个批量归一化处理（BN）和一个激活函数（Leaky），YOLOv4的主干网络CSPDarknet53中，使用Mish代替了原来的Leaky ReLU。常见的激活函数：Sigmoid、tanh、Leaky ，ReLU、Mish。 batch、上采样（下采样）、卷积核和激活函数的概念，卷积核（filters）和滤波器（kernels）的区别。详细参考极本穷源2 123456789101112131415#卷积层[convolutional]batch_normalize=1 #是否做归一化处理，传统的归一化公式 (number - mean) / std， mean表示均值， std表示标准差filters=18 #卷积核个数（输出的特征图的维度）只修改每个yolo上的第一个conv层size=3 #卷积核尺寸3×3stride=2 #卷积运算时的步长pad=1 #如果pad为0,padding由 padding参数指定。如果pad为1，padding大小为size/2activation=leaky #激活函数 routeroute应该就是全连接层，起到连接的作用，将不同卷积层输出的特征进行连接。本质上它是一个融合层，它的作用是在当前层引出之前卷积所得到的特征层。全连接层的作用就是将网络学到分布式特征映射到样本标记空间。 参考YOLO中的route层 layers = -6,-1表示将向前数的第6层与第1层相连接，完成特征的传递。 layer = -2 ，表示引出前两层的conv输出的特征图。 123[route]layers = -6,-1 maxpool （池化层）12345[maxpool]size=2stride=2 网络模型的构建当然，只有cfg配置文件是远远不够的。配置文件本质上调用了一大堆定义好的函数，改变传入函数的参数实现不同的功能及效果。这些函数主要包括 /src下的 我们从最常用的 detector命令切入，简单分析下调用规则。从以下命令不难发现，这些命令是运行了当前文件夹下的darknet.c文件。 1234567891011121314#训练./darknet detector train#map计算./darknet detector map#图片检测./darknet detector test#聚类先验框./darknet detector calc_anchors#视频检测./darknet detector demo 打darknet.c看下： 123456789101112131415161718191.先看main函数#先是一堆#ifndef防止多重定义,接下来就是一大堆if else ifelse if (0 == strcmp(argv[1], &quot;detector&quot;))&#123; run_detector(argc, argv);//492行 当./darknet后面的命令为 detector 时，调用函数run_dector()2.右键这个函数转到定义：void run_detector(int argc, char **argv)//1966行和main.c一样先定义一大堆，然后就是if else if直接找到关键词 test train map...if (0 == strcmp(argv[2], &quot;test&quot;)) test_detector(datacfg, cfg, weights, filename, thresh, hier_thresh, dont_show, ext_output, save_labels, outfile, letter_box, benchmark_layers);//2038 else if (0 == strcmp(argv[2], &quot;train&quot;)) train_detector(datacfg, cfg, weights, gpus, ngpus, clear, dont_show, calc_map, thresh, iou_thresh, mjpeg_port, show_imgs, benchmark_layers, chart_path); else if (0 == strcmp(argv[2], &quot;valid&quot;)) validate_detector(datacfg, cfg, weights, outfile); else if (0 == strcmp(argv[2], &quot;recall&quot;)) validate_detector_recall(datacfg, cfg, weights); else if (0 == strcmp(argv[2], &quot;map&quot;)) validate_detector_map(datacfg, cfg, weights, thresh, iou_thresh, map_points, letter_box, NULL); else if (0 == strcmp(argv[2], &quot;calc_anchors&quot;)) calc_anchors(datacfg, num_of_clusters, width, height, show); 果然都能找到定义了好的detector函数：（参考已有资料理解） 123456789101112131415//detector.c3.右键test_detector找到函数定义：void test_detector(char *datacfg, char *cfgfile, char *weightfile, char *filename, float thresh,float hier_thresh, int dont_show, int ext_output, int save_labels, char *outfile, int letter_box, int benchmark_layers)//1626行void train_detector(char *datacfg, char *cfgfile, char *weightfile, int *gpus, int ngpus, int clear, int dont_show, int calc_map, float thresh, float iou_thresh, int mjpeg_port, int show_imgs, int benchmark_layers, char* chart_path)//26行float validate_detector_map(char *datacfg, char *cfgfile, char *weightfile, float thresh_calc_avg_iou, const float iou_thresh, const int map_points, int letter_box, network *existing_net)//940行void calc_anchors(char *datacfg, int num_of_clusters, int width, int height, int show)//1443行//视频检测比较特殊，单独定义在 /src/demo.cvoid validate_detector(char *datacfg, char *cfgfile, char *weightfile, char *outfile)//643行 以 train_detector（）为例： 12345678910111213//detector.c//读取cfg文件list *options = read_data_cfg(datacfg); //28行 //根据train.txt找到训练的图片char *train_images = option_find_str(options, &quot;train&quot;, &quot;data/train.txt&quot;);//用训练集合作为验证图片char *valid_images = option_find_str(options, &quot;valid&quot;, train_images);//训练好的权重文件存储在/backup/char *backup_directory = option_find_str(options, &quot;backup&quot;, &quot;/backup/&quot;); 大概就是从这里调的cfg配置文件吧，其他命令也是类似的。参考yolov3网络模型构建。","categories":[{"name":"极本穷源","slug":"极本穷源","permalink":"http://example.com/categories/%E6%9E%81%E6%9C%AC%E7%A9%B7%E6%BA%90/"}],"tags":[{"name":"yolov4-tiny","slug":"yolov4-tiny","permalink":"http://example.com/tags/yolov4-tiny/"},{"name":"cfg文件解读","slug":"cfg文件解读","permalink":"http://example.com/tags/cfg%E6%96%87%E4%BB%B6%E8%A7%A3%E8%AF%BB/"},{"name":"网络模型构建","slug":"网络模型构建","permalink":"http://example.com/tags/%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E6%9E%84%E5%BB%BA/"}],"author":"Ethan"},{"title":"YOLOv4-tiny训练数据集（kmeans聚类anchors）","slug":"YOLOv4-tiny训练数据集（kmeans聚类anchors）","date":"2022-03-03T06:00:00.000Z","updated":"2022-05-05T01:55:20.944Z","comments":true,"path":"2022/03/03/YOLOv4-tiny训练数据集（kmeans聚类anchors）/","link":"","permalink":"http://example.com/2022/03/03/YOLOv4-tiny%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E9%9B%86%EF%BC%88kmeans%E8%81%9A%E7%B1%BBanchors%EF%BC%89/","excerpt":"","text":"YOLOv4-tiny训练数据集（kmeans聚类anchors）接着上篇开工总结，上次总结到想训练yolov4-tiny检验下模型对小目标的感知能力，白嫖的GPU平台不得行。只好用自己的电脑训练数据了，训练起来也不算难。 网上有看到用Kmeans聚类计算先验框 可以有效的提升检测准确率。 在darknet中源码默认附带了计算的命令： yolov4(tiny)聚类先验框yolov4-tiny: ./darknet detector calc_anchors data/train.data -num_of_clusters 6 -width 416 -height 416 yolov4: /darknet detector calc_anchors data/train.data -num_of_clusters 9 -width 416 -height 416 将聚类后得到的anchor替换cfg配置文件里对应的参数，再进行数据训练查看效果。 训练效果对比总共训练两次： ①未使用kmeans聚类，map达到60%左右 ②使用kmeans聚类预测框，map达到90%左右 遇到的坑之前在windows下训练就遇到过opencv报错 -&gt; video stream stopped 解决方法：查了很多资料，有说卸载opencv重新安装，重新编译darknet的。感觉都不靠谱，按照以往经验这就是突然安装什么软件或者运行什么程序导致opencv文件丢失的，之前安装opencv用的是源码编译安装，这次直接到安装目录下重新执行安装命令，问题得以解决。","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"炼丹笔记","slug":"深度学习/炼丹笔记","permalink":"http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%82%BC%E4%B8%B9%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"kmeans","slug":"kmeans","permalink":"http://example.com/tags/kmeans/"},{"name":"bounding boxs","slug":"bounding-boxs","permalink":"http://example.com/tags/bounding-boxs/"},{"name":"yolov4-tiny","slug":"yolov4-tiny","permalink":"http://example.com/tags/yolov4-tiny/"},{"name":"anchor boxes","slug":"anchor-boxes","permalink":"http://example.com/tags/anchor-boxes/"}],"author":"Ethan"},{"title":"深度学习模型转换技术","slug":"深度学习模型转换技术","date":"2022-02-28T00:46:50.000Z","updated":"2022-03-10T01:10:44.089Z","comments":true,"path":"2022/02/28/深度学习模型转换技术/","link":"","permalink":"http://example.com/2022/02/28/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E8%BD%AC%E6%8D%A2%E6%8A%80%E6%9C%AF/","excerpt":"","text":"深度学习模型转换技术什么是深度学习模型转换首先需要明白深度学习模型的概念，在使用深度学习深度学习模型是指一种包含深度神经网络结构的机器学习模型。算法工程师使用某种深度学习框架构建好模型，经调参和训练优化后，将最终生成的网络参数和模型结构一并保存，得到的文件即为可用于前向推理的模型文件。不同深度学习框架训练得到的模型文件的格式不尽相同，但完整的模型文件一般都包含了张量数据、运算单元和计算图等信息。 之前在复现jetson nano上部署yolov4-tiny，实时检测目标时用到了两次模型转换，很疑惑为啥要转换模型，今天就来学习下模型转换相关技术，用到的两次模型准换： ①yolo转onnx ​ ②onnx转trt 什么是onnx?+了解一下：深度学习模型转换与部署那些事(含ONNX格式详细分析) 什么是tensorRT？为什么要模型转换目的是为了提速，简单的来说 如何进行模型转换tensorRT","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"炼丹笔记","slug":"深度学习/炼丹笔记","permalink":"http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%82%BC%E4%B8%B9%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"onnx","slug":"onnx","permalink":"http://example.com/tags/onnx/"},{"name":"yolo","slug":"yolo","permalink":"http://example.com/tags/yolo/"},{"name":"tensorrt","slug":"tensorrt","permalink":"http://example.com/tags/tensorrt/"}],"author":"Ethan"},{"title":"开工总结(padlepadle,yolo-fasterV2)","slug":"padlepadle(百度飞桨)","date":"2022-02-22T13:39:50.000Z","updated":"2022-03-09T03:05:02.339Z","comments":true,"path":"2022/02/22/padlepadle(百度飞桨)/","link":"","permalink":"http://example.com/2022/02/22/padlepadle(%E7%99%BE%E5%BA%A6%E9%A3%9E%E6%A1%A8)/","excerpt":"","text":"开工总结(padlepadle,yolo-fasterV2)问题概要终于在春节前西安疫情消退，回家简短的休整后又来搬砖了。这段时间主要完成节前留下的问题：原使用yolov4-Tiny（TensorRT加速）在jetson nano上达到实时检测（FPS：40）的效果，后在win10下用yolov3训练数据测试效果mAP达到91.07%，用训练好的yolov3权重文件测试在nano的帧数只有8帧左右（不能用v3训练的权重测试v4-tiny检测不出来，可能是网络结构不同导致的）,而预期目标要求在nano上满足准确率高的前提下实时的效果。参考下图在nano上用trt加速的各种算法帧数测试效果。 解决思路：①提升yolov4-Tiny检测准确率 ②通过剪枝压缩等操作提升yolov3在nano上的的检测速度 方法实施：yolov3网络模型较为复杂，剪枝压缩不好操作，那就先用yolov4-tiny训练下数据看下效果。受限于每次训练数据电脑就用不了这一因素，最近有看到白嫖百度GPU服务器在线训练的内容，有这种好事当然要冲，给我也整一个。简单完成几个小任务算力卡就到手了，接下来就可以准备在飞桨的AI studio在线用yolov4-Tiny训练自己的数据集了。 国产深度学习开源框架—飞桨padlepadle(百度飞桨)—国内最大的开源深度学习框架，是可以与PyTorch、TensorFlow掰手腕的国产框架佼佼者，简单了解下。顺便了解下其他国产深度学习平台。 飞桨能干啥？①超多深度学习免费课程 ②在线跑项目 ③创建自己的项目并在线训练数据 飞桨怎么用？①本地使用，推荐win10下安装conda，可以安装各种想要的虚拟环境 ②在线创建项目并运行 结果在线创建了项目并上传了自己的数据集，下载darknet源码，编译后报错。可能和cuda版本或者显卡驱动有关。 白嫖的GPU服务器sudo权限没有给解决起这个报错有点受阻，后面再百度试试实在不行还是用自己的电脑跑起来省事。 后面查了下百度aistudio早已不再支持tensorflow、pytorch、mxnet等框架，果然白嫖来的不会完美。不过在aistuidio从学习基础到上手跑项目代码确实是良心国产。 Yolo-fasterV2 训练自己的数据目的方法按照球球大佬在readme.md中的说明，之前标注的数据集就可以用。 安装 requirements 环境，测试一张图片看看效果.可能会遇到torch和cuda不版本匹配的问题，报错如下： 1RunTimeError: CUDA error: no kernel image is available for execution on the device 参考这篇解决。 按照目录结构，准备相应文件。 修改下自己的 .data文件，设定训练参数,删除文件中的注释 12345678910111213141516171819202122[name]model_name=obj # model name[train-configure]epochs=500 # train epichssteps=150,250 # Declining learning rate stepsbatch_size=64 # batch sizesubdivisions=1 # Same as the subdivisions of the darknet cfg filelearning_rate=0.001 # learning rate[model-configure]pre_weights=None # The path to load the model, if it is none, then restart the trainingclasses=80 # Number of detection categorieswidth=352 # The width of the model input imageheight=352 # The height of the model input imageanchor_num=3 # anchor numanchors=12.64,19.39, 37.88,51.48, 55.71,138.31, 126.91,78.23, 131.57,214.55, 279.92,258.87 #anchor bias[data-configure]train=/media/qiuqiu/D/coco/train2017.txt # train dataset path .txt fileval=/media/qiuqiu/D/coco/val2017.txt # val dataset path .txt file names=./data/coco.names # .names category label file yolo-fatest的设计初衷是因为Darknet CPU推理效率优化不好，所以为了能够在像运算能力较低的ARM-cpu,虽然说“更快、更轻“，但训练出来的结果不尽人意。造成这一结果的原因太多了，可能是样本数量、学习率、训练轮次。 后面还是再试下yolov4-tiny的训练效果吧。 深度学习的宏观框架——训练（training）和推理（inference）及其应用场景","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"炼丹笔记","slug":"深度学习/炼丹笔记","permalink":"http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%82%BC%E4%B8%B9%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"飞桨","slug":"飞桨","permalink":"http://example.com/tags/%E9%A3%9E%E6%A1%A8/"},{"name":"Yolo-faster","slug":"Yolo-faster","permalink":"http://example.com/tags/Yolo-faster/"}],"author":"Ethan"},{"title":"疫情下的炼丹笔记(yolov3计算map)🎈","slug":"疫情下的炼丹笔记","date":"2022-01-05T08:03:50.000Z","updated":"2022-03-03T05:52:03.614Z","comments":true,"path":"2022/01/05/疫情下的炼丹笔记/","link":"","permalink":"http://example.com/2022/01/05/%E7%96%AB%E6%83%85%E4%B8%8B%E7%9A%84%E7%82%BC%E4%B8%B9%E7%AC%94%E8%AE%B0/","excerpt":"","text":"前言好久没写，最近发生的事情太多了，简要汇总下吧。12月22日，西安要封城的消息传遍了VX群，随即收拾资料准备居家办公做好持久战的准备。短短一周防疫政策的不断变化让很多物资储备不足的小伙伴慌了起来，当时去屯物资的时候还在疑惑，怎么大爷大妈扛着整袋面粉，盐也要买好几袋。“ 菜量充足，不必哄抢。一键下单，送到你家。” 这有问题吗？没有啊！有问题的是老实人你。。 只能说大爷大妈的预判YYDS。 后来嘛，就是居家封闭，定期核酸检测。醒来第一件事就是查看核酸检测结果，看着每天新增的病例数，每个人都期盼着拐点的出现。ww没想到去年屯的五谷派上了用场，还好在家学会了几道菜，这三板斧解决吃饭难题。因为这波疫情，整天被圈在个水泥盒子里的人也被联系了起来。夜深人静，群里谈及梦想，都挺不容易。“都睡了几天了 该有不该有的梦里都有了 就是没能走出这个房子”，焯！彩票梦，老板梦的气泡一个个的被扎破。生活嘛，总是让一批又一批不知死活的小b崽子在不知不觉中成长，耳机里又响起 “想学功夫 修炼仙术 先征服这条山路 我在三清观里录歌 旋律和韵脚兼顾” 《崂山道士》—Masiwei。 新年了，新年了。被关在这里，只能用一场酩酊大醉送走2021，从炸金花玩到摇骰子，到最后的真心话大冒险。新的一年，只希望自己平安喜乐，一切都尽快的回归正轨。一周多了，睡也睡够了玩也玩够了，是时候充实自己了。古有“天大寒，砚冰坚，手指不可屈伸，弗之怠”，每想到这句诗就找不到不学习的理由。 接着之前的工作，初识YOLO算法后对采集的数据进行处理。这段时间的规划是：制作数据集、训练模型、模型优化。这次的数据训练是在Windows下采用YOLOV3训练自己的数据，达到对目标的较高可靠度的准确识别。 制作数据集使用labelimg标注工具，对图片中感兴趣的目标进行标注，为后续的训练提供目标信息在图片中的信息,其中主要包括类别信息以及位置信息：两个点坐标（xmin,ymin）（xmax,ymax） 低对比度小目标识别检测：上图目标像素大小大概为371 X 240 ，原图片像素为2000w像素：5472 X 3648） ①labelimg标注后生成对应的xml文件 ②使用python脚本将位置信息转换为YOLO训练所需要的数据格式，生成对应的txt文件。最后将图片与txt文件都放输入data\\obj目录下，方便后续使用。 ③新建一个类别文件obj.names （内容只需要填写自己的类别名称，中文名称需要做数据集是中文标签，且在源代码中修改相关文件并重新编译）, 新建一个图片目录文件train.txt, 都放到data/目录下 总的来说，训练的时候会用到obj.data文件。而obj.data写入了train.txt以及obj.names,train.txt又写入了标注好的图片路径，从而达到一连串的调用。 训练模型准备工作：①在修改训练轮次 max_batches = 8000，按照以往经验200张左右的图片，训练8000轮就够了 ②Windows版的darknet-YOLOV3提供了map命令，可以一边训练数据集一边计算训练集的map以寻找最优模型。 命令如下： 1darknet.exe detector train data\\obj.data yolo-obj.cfg darknet53.conv.74 -map 报错记录：错误信息说的是obj.data里的test.txt没有对应的测试数据 valid = data/test.txt 改为 valid = data/train.txt 开始训练：这次使用map命令边训练边计算 average perscion，如红线所示，极其不稳定。 群里问了下出现这种情况有两种可能：训练的数据太少了（确实少），batchsize设置的较小（有待研究） 这个时候停止训练，计算一下测试集的mAP。 测试集的mAP计算①标注测试集对应的目标信息，和训练集一样用labelimg生成xml文件，转换为txt文件。 ②新建test.txt,和train.txt一样写入待测试图片的路径，通过调用obj.data里的valid = data/test.txt实现对测试图片的调用。 ③测试命令如下： 1darknet.exe detector map data\\obj.data yolo-obj.cfg .\\backup\\yolo-obj_last.weights -thresh 0.25 -iou_thresh 0.45 测试结果表明：mAP(只有一个类别所以平均准确率AP = mAP) 达到惊人的91.07% 其中，测试结果参数解析： 123456789101112 TP：正样本预测为正样本​ FP：负样本预测为正样本​ TN：负样本预测为负样本​ FN: 正样本预测为负样本​ 精确率 = 94%（precision）,即用训练好的模型去预测测试集,预测结果与实际相比有对有错，精确率就是实际正确预测占模型认为正确预测的比例。 计算公式：precision = TP/(TP+FP)​ 召回率 = 92% （recall），即用训练好的模型预测测试集,这个模型会有四类预测结果，召回率就是实际正确预测占应该被预测出来的比例。 计算公式：recall = TP/(TP+FN)​ 交并比 = 69.74%（IoU），即预测边框与实际边框的交集与并集的比例。 测试效果图片检测：测试集里随便拉一张图片，执行如下命令，看下效果。 1darknet.exe detector test data\\obj.data yolo-obj.cfg .\\backup\\yolo-obj_last.weights .\\data\\Test\\121.jpg 视频检测：错误记录：video stream stopped ，大部分是缺少openCV相关文件。复制·openCV安装目录下的opencv_ffmpeg340_64.dll文件到darknet\\x64目录下，问题解决。 执行如下命令： 12345darknet.exe detector demo data\\obj.data yolo-obj.cfg .\\weights\\yolo-obj_last.weights .\\data\\Test\\mp4\\test2.avi 保存检测视频加上下面这一句 -thresh 0.25 -out_filename .\\data\\Test\\mp4\\test2_result.avi 视频检测效果 总结​ 深度学习，道阻且长。革命尚未成功，同志仍需努力！","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"炼丹笔记","slug":"深度学习/炼丹笔记","permalink":"http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%82%BC%E4%B8%B9%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"训练集","slug":"训练集","permalink":"http://example.com/tags/%E8%AE%AD%E7%BB%83%E9%9B%86/"},{"name":"新冠","slug":"新冠","permalink":"http://example.com/tags/%E6%96%B0%E5%86%A0/"},{"name":"封城","slug":"封城","permalink":"http://example.com/tags/%E5%B0%81%E5%9F%8E/"},{"name":"mAP","slug":"mAP","permalink":"http://example.com/tags/mAP/"}],"author":"Ethan"},{"title":"极本穷源：YOLO篇Ⅱ","slug":"极本穷源：YOLO篇Ⅱ","date":"2021-12-15T01:30:50.000Z","updated":"2022-02-15T01:43:30.507Z","comments":true,"path":"2021/12/15/极本穷源：YOLO篇Ⅱ/","link":"","permalink":"http://example.com/2021/12/15/%E6%9E%81%E6%9C%AC%E7%A9%B7%E6%BA%90%EF%BC%9AYOLO%E7%AF%87%E2%85%A1/","excerpt":"","text":"极本穷源：YOLO篇Ⅱ 上篇中我们提到了yolo的大概属性，今天接着总结一下yolo是基于什么样的背景发展而来。 YOLO是如何实现目标的识别检测？ 首先YOLO由多层网络组成以YOLOv3为例： yolov3 yolov3.cfg 结构组成卷积层+池化层+激活函数+全连接层 卷积层 卷积层由一组滤波器组成输入图像与滤波器进行卷积产生输出图像 (16 条消息) 如何理解卷积神经网络（CNN）中的卷积和池化？ - 知乎 (zhihu.com) 卷积核（filters）和滤波器（kernels）的区别 科普-深度学习中的卷积-卷积核和滤波器的区别 - 重大的小鸿 - 博客园 (cnblogs.com) filter和kernel之间的不同很微妙。很多时候，它们可以互换，所以这可能造成我们的混淆。那它们之间的不同在于哪里呢？一个”kernel”更倾向于是2D的权重矩阵。而’filter”则是指多个Kernel堆叠的3D结构。如果是一个2D的filter，那么两者就是一样的。但是一个3Dfilter, 在大多数深度学习的卷积中，它是包含kernel的。每个卷积核都是独一无二的，主要在于强调输入通道的不同方面 除了卷积层，卷积网络也经常使用池化层来缩减模型的大小，提高计算速度，同时提高所提取特征的鲁棒性.因为经过池化后，得到的是 概要统计特征 。它们不仅 具有低得多的维度 (相比使用所有提取得到的特征)，同时还会 改善结果(不容易过拟合) 池化层 池化层目的是进行特征选择，图像经过卷积提取的特征图会产生很多冗余特征，主要采用平均池化和最大池化。 下采样和池化应该是包含关系，池化属于下采样，而下采样不局限于池化，如果卷积 stride=2，此时也可以把这种卷积叫做下采样 下采样和池化的区别 池化 = 涨水 池化的过程 = 升高水位（扩大矩阵网格） 池化的目的是为了得到物体的边缘形状 可以想象水要了解山立体的形状，水位低时得出山脚的形状，水位中等时得出山腰的形状，水位高时得出山顶的形状，三点就可以大致描出山的简笔画 而卷积的过程是区分哪里是水，哪里是山 对于网络结构而言，上面的层看下面的层经过 pooling 后传上来的特征图，就好像在太空上俯瞰地球，看到的只有山脊和雪峰。这即是对特征进行宏观上的进一步抽象 激活函数 激活函数是啥？（Sigmoid函数、tanh函数、Relu函数） (2条消息) 神经网络之激活函数_August-us的博客-CSDN博客_神经网络激活函数 (1条消息) 激活函数的作用_atarik@163.com-CSDN博客_激活函数的作用 (1条消息) 常用激活函数（激励函数）理解与总结_tyhj_sf的博客空间-CSDN博客_激活函数​ 在YOLOv3中，每个卷积层之后包含一个批量归一化层和一个Leaky ReLU。而在YOLOv4的主干网络CSPDarknet53中，使用Mish代替了原来的Leaky ReLU。Leaky ReLU和Mish激活函数的公式与图像如下： Softmax Softmax 函数不仅可以将输出值映射到[0,1]区间，还满足所有的输出值之和为 1 的特性。如下图的例子，输出层的输出为[2.,1.,0.1]，经过 Softmax 函数计算后，得到输出为[0.7,0.2,0.1]，可以看到每个值代表了当前样本属于每个类别的概率，概率值之和为 1。 通过 Softmax 函数可以将输出层的输出转译为类别概率，在多分类问题中使用的非常频繁 另外，在softmax函数多分类问题中，若损失函数选用交叉熵，则下降梯度计算起来将会非常方便，使得网络训练过程中的迭代计算复杂度大大降低。 全连接层 全连接层将学到的“分布式特征表示”映射到样本标记空间 假设你是一只小蚂蚁，你的任务是找小面包。你的视野还比较窄，只能看到很小一片区域。当你找到一片小面包之后，你不知道你找到的是不是全部的小面包，所以你们全部的蚂蚁开了个会，把所有的小面包都拿出来分享了，全连接层就是这个蚂蚁大会。 yolo基础知识 概念解释： 训练神经网络:Batch、Epoch和Iteration Batch（批 / 一批样本）：将整个训练样本分成若干个Batch。 Batch_Size（批大小）：每批样本的大小。 Iteration（一次迭代）：训练一个Batch就是一次Iteration（这个概念跟程序语言中的迭代器相似） Epoch（时期）：当一个完整的数据集通过了神经网络一次并且返回了一次，这个过程称为一次&gt;epoch。（也就是说，所有训练样本在神经网络中都 进行了一次正向传播 和一次反向传播 ）再通俗一点，一个Epoch就是将所有训练样本训练一次的过程。 随着epoch数量增加，神经网络中的权重的更新次数也在增加，曲线从欠拟合变得过拟合。 那么，问题来了，几个epoch才是合适的呢？ 不幸的是，这个问题并没有正确的答案。对于不同的数据集，答案是不一样的。但是数据的多样性会影响合适的epoch的数量。比如，只有黑色的猫的数据集，以及有各种颜色的猫的数据集。 梯度下降算法原理讲解——机器学习 梯度是微积分中一个很重要的概念，之前提到过梯度的意义 在单变量的函数中，梯度其实就是函数的微分，代表着函数在某个给定点的切线的斜率 在多变量函数中，梯度是一个向量，向量有方向，梯度的方向就指出了函数在给定点的上升最快的方向 这也就说明了为什么我们需要千方百计的求取梯度！我们需要到达山底，就需要在每一步观测到此时最陡峭的地方，梯度就恰巧告诉了我们这个方向。梯度的方向是函数在给定点上升最快的方向，那么梯度的反方向就是函数在给定点下降最快的方向，这正是我们所需要的。所以我们只要沿着梯度的方向一直走，就能走到局部的最低点 学习率 学习率越低，损失函数的变化速度就越慢，容易过拟合。虽然使用低学习率可以确保我们不会错过任何局部极小值，但也意味着我们将花费更长的时间来进行收敛，特别是在被困在局部最优点的时候。而学习率过高容易发生梯度爆炸，loss振动幅度较大，模型难以收敛。下图是不同学习率的loss变化，因此，选择一个合适的学习率是十分重要的。 通道channel、特征图feature map、过滤器filter和卷积核kernel （BN）批量归一化全面解析,backbone：主干网络.head：head是获取网络输出内容的网络，neck:是放在backbone和head之间的，是为了更好的利用backbone提取的特征.GAP：Global Average Pool全局平均池化（AP）平均预测 上采样，下采样 《图像的上采样（upsampling）与下采样（subsampled）》 https://blog.csdn.net/stf1065716904/article/details/78450997?utm_source=app&amp;app_version=4.17.2&amp;code=app_1562916241&amp;uLinkId=usr1mkqgl919blen 缩小图像（或称为下采样（subsampled）或降采样（downsampled））的主要目的有两个：1、使得图像符合显示区域的大小；2、生成对应图像的缩略图。 放大图像（或称为上采样（upsampling）或图像插值（interpolating））的主要目的是放大原图像,从而可以显示在更高分辨率的显示设备上。 对图像的缩放操作并不能带来更多关于该图像的信息, 因此图像的质量将不可避免地受到影响。然而，确实有一些缩放方法能够增加图像的信息，从而使得缩放后的图像质量超过原图质量的。 Anchor Boxes机制 论文学习 FoveaBox: Beyond Anchor-based Object Detector_何以解忧唯有杜康的博客-CSDN博客_foveabox YOLO会将输入的图片分成S*S个网格，每个小网格会生成n个anchor Box。图像的真实框会和图像中心点所在的小网格生成的anchor box做IOU计算。回归出来的框就是Bounding Box（也就是网络输出的框，他与真实框和anchor Box都有差距） 通过引入anchor box，一方面，模型学习到的是物体真实边框与对应的anchor box的偏移量，而不是目标物体在图像中的绝对坐标，保证了检测任务的平移不变性；另一方面，通过这种对齐，可以使模型对多尺度物体检测的训练变得容易，因为物体边框对相应anchor box的偏移量的值分布于有限范围内。 讲这么多直接上操作感受下吧，打开YOLOv4-Tiny的.cfg文件 NMS调参 288.cfg ignore_thresh = .7 beta_nms=0.7 result 288.cfg ignore_thresh = .7 beta_nms=0.8 result 416.cfg ignore_thresh = .7 beta_nms=0.7 result 416.cfg ignore_thresh = .7 beta_nms=0.5 result","categories":[{"name":"极本穷源","slug":"极本穷源","permalink":"http://example.com/categories/%E6%9E%81%E6%9C%AC%E7%A9%B7%E6%BA%90/"}],"tags":[{"name":"yolov3","slug":"yolov3","permalink":"http://example.com/tags/yolov3/"},{"name":"网络结构","slug":"网络结构","permalink":"http://example.com/tags/%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84/"}],"author":"Ethan"},{"title":"极本穷源：YOLO篇Ⅰ","slug":"极本穷源：YOLO篇Ⅰ","date":"2021-12-14T01:30:50.000Z","updated":"2022-02-15T01:56:53.298Z","comments":true,"path":"2021/12/14/极本穷源：YOLO篇Ⅰ/","link":"","permalink":"http://example.com/2021/12/14/%E6%9E%81%E6%9C%AC%E7%A9%B7%E6%BA%90%EF%BC%9AYOLO%E7%AF%87%E2%85%A0/","excerpt":"","text":"极本穷源：YOLO篇Ⅰ 总听到神经网络 什么是神经网络？ 1.1.1 什么是神经网络 - 床长人工智能教程 (captainbed.net) 人工神经网络是受到人类大脑结构的启发而创造出来的，这也是它能拥有真智能的根本原因。在我们的大脑中，有数十亿个称为神经元的细胞，它们连接成了一个神经网络。 层数越多那么构造的神经网络就越复杂，训练深度神经网络的过程就叫做深度学习 AI”炼丹”是啥 深度学习就像炼丹，没啥理论，纯靠实验，要有很多比较好的显卡等设备，动不动就要训练好几天的数据模型。 这段时间在学习YOLO算法，相信很多小伙伴和我一样，机器学习深度学习，傻傻分不清楚。 遇到这种情况怎么说，旋即打开浏览器搜索“机器学习”，wdnmd,“学习”居然分了这么多的类：机器学习、监督学习、非监督学习、强化学习、迁移学习、深度学习（DNN、CNN、RNN、LSTM、GAN）。脑瓜子嗡嗡的，这种感觉就像…“马肾么妹，马冬梅啊，大爷！”。世上无难事，只要肯放弃。从入门到放弃只需轻轻一点，关闭浏览器冷静一下。 重新来会会这些“牛鬼蛇神”，一张图了解下它们的关系 传统机器学习的模型结构 线性回归 逻辑回归 决策树 支持向量机 贝叶斯模型 正则化模型 集成模型 神经网络 机器学习 监督学习 非监督学习 强化学习 迁移学习 深度学习 DNN（深度神经网络）网络拓扑结构分类 RNN（递归神经网络） LSTM（长期短期记忆网络） GAN（生成对抗网络） CNN（卷积神经网络） 以卷积为核心的一大类网络 CNN、RCNN、YOLO等和Alexnet、VGG等的关系是什么？ - 知乎 (zhihu.com) 图像分类 LeNet、AlexNet、VGG、GoogleNet、ResNet 目标检测 RCNN、Fast RCNN、Faster RCNN、SSD、Mask-RCNN YOLO 千呼万唤始出来，“YOLO”与机器学习的关系可谓是千丝万缕。 语义分割与实例分割 图像分类、目标检测、语义分割、实例分割和全景分割的区别 全景分割 （全景分割是语义分割和实例分割的结合。跟实例分割不同的是：实例分割只对图像中的object进行检测，并对检测到的object进行分割，而全景分割是对图中的所有物体包括背景都要进行检测和分割。） 语义分割 通常意义上的目标分割指的就是语义分割 语义分割（下图左）就是需要区分到图中每一点像素点，而不仅仅是矩形框框住了。但是同一物体的不同实例不需要单独分割出来。对下图左，标注为人，羊，狗，草地。而不需要羊1，羊2，羊3，羊4，羊5等。 实例分割 实例分割：其实就是目标检测和语义分割的结合。相对目标检测的边界框，实例分割可精确到物体的边缘；相对语义分割，实例分割需要标注出图上同一物体的不同个体（羊1，羊2，羊3…） 目前常用的实例分割算法是Mask R-CNN。 目标检测 目前常用的目标检测算法有Faster R-CNN和基于YOLO的目标检测的算法 图像分类 图像分类：就是对图像判断出所属的分类，比如在学习分类中数据集有人（person）、羊（sheep）、狗（dog）和猫（cat）四种，图像分类要求给定一个图片输出图片里含有哪些分类，比如下图的例子是含有person、sheep和dog三种。 揭开“YOLO”的神秘面纱 从2018年Yolov3年提出的两年后，在原作者声名放弃更新Yolo算法后，俄罗斯的Alexey大神扛起了Yolov4的大旗，然后不久又出现了Yolov5,而到了2021年，就在大家质疑Yolo系列该如何改进时？旷视科技又发布了Yolox算法，感兴趣的可以参考这篇博客了解。 2020年2月份YOLO之父Joseph Redmon宣布退出计算机视觉的研究的时候，很多人都以为目标检测神器YOLO系列就此终结。 没想到的是, 2020年4月份曾经参与YOLO项目维护Alexey Bochkovskiy带着论文《Optimal Speed and Accuracy of Object Detection》和代码在Github上重磅开源！YOLOv4正式发布！ 令我们更没想到的是！！！2020年6月份，短短两个月！Ultralytics LLC 公司的创始人兼 CEO Glenn Jocher 在 GitHub 上发布了 YOLOv5 的一个开源实现，标志着YOLOv5的到来！ 现如今的YOLO算法在各位大佬的神奇改造下，在保持算法准确性的前提下轻量化网络模型，使其能够部署到像树莓派、RK3399等低算力的设备上并得到比较不错的检测速度与准度。 那么这些大佬们平时在自己的岗位上都需要干些啥呢？ 1.基于提出需求设计组合算法即策略解决问题，不限于深度学习，传统视觉，算法策略，大部分需求都是组合算法解决的，例如检测分类姿态等多模态模型组合并配合一些传统算法解决问题(pytorch/caffe opencv) 2.训练数据采集方案的设计，标注规则的指定以及数据审核 3.快速实现算法demo并验证算法逻辑策略部分以及评估自测(Python) 4.模型实际部署平台的性能资源占用和效率评估，评估ok走下一步，否则返回3步骤针对优化验证， 4.基于c/c++完成算法sdk库开发，其中涉及到模型多平台移植部署(涉及到后端nn推理框架的选用，前后处理部分代码的编写)，代码高性能优化(simd cuda openc,openmpl…) 5.算法库文档编写，外发sdk库 (…..算法岗不是调参侠)机器学习算法工程师都要干些啥 那么YOLO是如何实现目标的识别检测？下一篇接着总结！","categories":[{"name":"极本穷源","slug":"极本穷源","permalink":"http://example.com/categories/%E6%9E%81%E6%9C%AC%E7%A9%B7%E6%BA%90/"}],"tags":[{"name":"yolo","slug":"yolo","permalink":"http://example.com/tags/yolo/"},{"name":"AI炼丹","slug":"AI炼丹","permalink":"http://example.com/tags/AI%E7%82%BC%E4%B8%B9/"},{"name":"神经网络","slug":"神经网络","permalink":"http://example.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"}],"author":"Ethan"},{"title":"图片上传测试👀","slug":"图片上传测试","date":"2021-12-10T08:30:50.000Z","updated":"2022-02-28T01:18:21.685Z","comments":true,"path":"2021/12/10/图片上传测试/","link":"","permalink":"http://example.com/2021/12/10/%E5%9B%BE%E7%89%87%E4%B8%8A%E4%BC%A0%E6%B5%8B%E8%AF%95/","excerpt":"","text":"","categories":[{"name":"图片","slug":"图片","permalink":"http://example.com/categories/%E5%9B%BE%E7%89%87/"}],"tags":[{"name":"沙滩企鹅","slug":"沙滩企鹅","permalink":"http://example.com/tags/%E6%B2%99%E6%BB%A9%E4%BC%81%E9%B9%85/"}],"author":"Ethan"},{"title":"如何优雅的写博客👀","slug":"如何优雅的写博客👀","date":"2021-12-10T01:30:50.000Z","updated":"2022-02-28T00:47:38.443Z","comments":true,"path":"2021/12/10/如何优雅的写博客👀/","link":"","permalink":"http://example.com/2021/12/10/%E5%A6%82%E4%BD%95%E4%BC%98%E9%9B%85%E7%9A%84%E5%86%99%E5%8D%9A%E5%AE%A2%F0%9F%91%80/","excerpt":"","text":"如何优雅的写博客👀起因最近发现幕布笔记原来越不稳定了，动不动就崩了，网上有传言幕布要倒闭了。这几天就又找了下其他办法，趁早转移图片素材存储空间。 之前在这篇博客里面说过，搭建好自己的博客网站后如何写博客。经过这段时间测试这个方法的可行性，结果上来看属实是有点麻烦了🤦‍♂️，先要在幕布写一遍笔记。为的是白嫖幕布的网络存储，然后用makdownPad排一下版，写博客界面如图二的界面写起博客极度不舒适。 经过今天看到了一种肥肠方便且舒服的markdown的正确打开方式✔ 它的原理很简单，还是之前说的图片存到免费图床上。然后用一个极度舒适markdown编辑软件自动的将博客中用到的图片上传到图床，那么它到底有多舒适呢，首先：①自动上传图片到图床②实时预览③人性化的主题以及专注模式和打字机模式。如下图所示，专注模式会将当前编辑行高亮显示。专不专注我不知道，zb这一块拿捏了。 那么如何实现呢： ①下载并安装相关 软件 Typora+PicGo（提取码：8848） ②配置gitee仓库设置，新建仓库 创建私人令牌，复制生成的密钥一会要用👻 ③打开PicGo点击安装可能会装不上，不要慌，去他的 GitHub 下一份源码，然后导入本地插件。 如图所示，配置一下。 ④配置 一下Typora 结果然后就可以愉快的写博客了🤔 参考文档：typora 图床配置方法-博客 (soolco.com)","categories":[{"name":"搭建个人博客","slug":"搭建个人博客","permalink":"http://example.com/categories/%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"}],"tags":[{"name":"PicGo","slug":"PicGo","permalink":"http://example.com/tags/PicGo/"},{"name":"gitee图床","slug":"gitee图床","permalink":"http://example.com/tags/gitee%E5%9B%BE%E5%BA%8A/"},{"name":"Typora","slug":"Typora","permalink":"http://example.com/tags/Typora/"}],"author":"Ethan"},{"title":"用于缓解OSA的医疗枕","slug":"用于缓解OSA的医疗枕","date":"2021-12-06T02:51:40.000Z","updated":"2021-12-15T07:37:09.791Z","comments":true,"path":"2021/12/06/用于缓解OSA的医疗枕/","link":"","permalink":"http://example.com/2021/12/06/%E7%94%A8%E4%BA%8E%E7%BC%93%E8%A7%A3OSA%E7%9A%84%E5%8C%BB%E7%96%97%E6%9E%95/","excerpt":"","text":"用于缓解OSA的医疗枕* 起因 由于工作原因，六月份的时候做了一款基于生物雷达、薄膜式压力传感器、LoRa、Stm32f103、电磁气阀、气泵等电子元器件的缓解OSA（阻塞性睡眠呼吸暂停）的医疗枕头。现将大概原理总结如下： * 目的 简单说明下这款设计的意义：众所周知，很多人在睡觉的时候会打呼，从医学角度解释的话是因为患者在睡眠时发生了呼吸阻塞引起打呼的发生。那么有人就要说了，不就是打呼嘛，多大个事！这有问题吗？没有问题。很不幸啊，鄙人在大学期间和一个体重较重的同学同住过一个寝室，每次睡觉都要赶在他睡着之前睡，他的呼噜打的那叫一个地道！好几次打呼时发生了阻塞性睡眠呼吸暂停，直接一口气没上来把自己憋醒了。较为严重的症状会引起肺功能失调、哮喘等疾病，因此设计一款非接触式的睡眠呼吸暂停监测及缓解的枕头是极其有必要的！ * 方法 原理说明：简单来说，通过生物雷达实时监测人体呼吸信号，使用Stm32单片机将模拟信号转换为数字信号，做数据处理判断后做出呼吸状态评估，进而通过LoRa无线通信将这一结果反馈至缓解装置（缓解装置为一个由气泵、气囊、电磁气阀、Stm32单片机、LoRa、薄膜式压力传感器组成的医疗枕头）。当缓解装置接收到来自监测端的OSA信号时，通过薄膜式压力传感器判断人体头部位置，从而触发电磁气阀为对应的气囊充气，推动患者头部对头部睡眠姿势做出改变，以达到缓解OSA的目的。电路图如下: 硬件组成： 薄膜式压力传感器： 生物雷达、STM32、HC05蓝牙（后改蓝牙） 气泵、电磁气阀 * 结果 采用非接触式的呼吸监测，减少了患者佩戴各种监测仪器带来的不便与影响，实际测试表明整套的流程走完是没有问题，然而因为考虑到气囊充气的力度，这次选择的鱼缸供氧的气泵，噪音较大。除此之外，程序上的一些小bug也没来得及改完就被强行收工。最终效果如下图： * 结论 当一个人去解决一大堆需求时，你能做的就是多动脑，勤动手，实在不会的就简化需求！以前压根没听说过电磁气阀这类东西，一个劲的按照自己的想法搜索合适的硬件选型，用鱼缸增氧的气泵也是处于给的时间并不多的原因。总之，干就完了，奥利给！","categories":[{"name":"单片机","slug":"单片机","permalink":"http://example.com/categories/%E5%8D%95%E7%89%87%E6%9C%BA/"}],"tags":[{"name":"OSA","slug":"OSA","permalink":"http://example.com/tags/OSA/"},{"name":"生物雷达","slug":"生物雷达","permalink":"http://example.com/tags/%E7%94%9F%E7%89%A9%E9%9B%B7%E8%BE%BE/"},{"name":"呼吸暂停","slug":"呼吸暂停","permalink":"http://example.com/tags/%E5%91%BC%E5%90%B8%E6%9A%82%E5%81%9C/"},{"name":"薄膜式压力传感器","slug":"薄膜式压力传感器","permalink":"http://example.com/tags/%E8%96%84%E8%86%9C%E5%BC%8F%E5%8E%8B%E5%8A%9B%E4%BC%A0%E6%84%9F%E5%99%A8/"},{"name":"LoRa","slug":"LoRa","permalink":"http://example.com/tags/LoRa/"}]},{"title":"四旋翼无人机组装","slug":"四旋翼无人机组装","date":"2021-12-05T13:51:20.000Z","updated":"2021-12-13T01:58:52.910Z","comments":true,"path":"2021/12/05/四旋翼无人机组装/","link":"","permalink":"http://example.com/2021/12/05/%E5%9B%9B%E6%97%8B%E7%BF%BC%E6%97%A0%E4%BA%BA%E6%9C%BA%E7%BB%84%E8%A3%85/","excerpt":"","text":"四旋翼无人机组装 去年夏天由于工作需要，在淘宝购买了一款拉线版四旋翼无人机开发套件。简单介绍下这款套件，如下图所示无人机主要包括机架、电机、电调、分电板、飞控、GPS导航（罗盘指南针）、电源、遥控器（接收机）、碳桨、抛投器等。 机架和浆叶均采用了碳钎维材料，目的是减轻自身重量，获得较好的续航性能。电机与电调配合飞控的控制指令使得无人机获得动力来源，电调的主要作用就是控制电机以合适的转速和功率转动，从而使得无人机平稳的飞行。飞控选配的是开源飞控pixhawk2.4.8，刚接触的小伙伴可能对APM、PIXHAWK、PX4这三者分不清楚，简单来说pixhawk是一款开源硬件APM和PX4都是烧写在该硬件上的固件程序。 遥控器和接收机是一套用于联通无人机状态、图像采集与地面站通信的通信设施，本次选配的是云卓T10套件（有配套的地面站软件）。电池选择的是8000mAh（6s 22.2v）的大容量供电，这为无人机提供了极其强悍的动力，可以后续观看电调校准感受下。它本质上还是定位为一款载重电力拉线无人机（4kg）,四旋翼无人机组装通过设置遥控器上的特定通道无线控制舵机工作，配合连杆的开合实现抛投功能。 * 目的 通过此次组装四旋翼无人机初步了解无人机原理构造，积累经验为后续开发打下基础。 * 方法 无人机到货后，心情是激动的、操作是无序的导致很多工作不得不返工，如下图飞行之前都先不用装桨叶。对新手来说拿到一堆零件后最忌讳的就是直接上手（天赋异禀的除外），先大概看一遍视频教程大致了解下步骤，然后边看教程边做。 动起手来也不难就是要心细点，主要包括：焊接、接线、拧螺丝、校准、测试。焊接：电池里的电流首先经过稳压模块接入到分电板，接着通过分电板正负极引脚分别分传输到四个电调，经过电调的调整控制四个电机以规定好的旋转方向工作从而为无人机提供动力，需要注意的是电调的线较粗控制好焊接面积，切记注意短路的问题。 接线：主要是电调与飞控通道的匹配（四个飞控通道对应四个电调）、GPS接线（直接插上）、接收机也给插上。校准：机架组装、焊接、接线都准备完毕后就需要对电调、罗盘、指南针、遥控器进行校准。电调校准时（不装桨叶）需要关注四个电机转向是否正确，下图所示为正确转向，出现侧飞或各种飞行不问首先检查电机转向，其次校准罗盘、GPS等。最后通过mission planner地面站软件分别对电调、罗盘、指南针、遥控器进行校准，设置遥控器的一个闲置通道为抛投器开关。 ​ 如果上述工作你都认真检查过了，就可以进行试飞了。尽量在空旷（卫星质量佳、人少）的环境测试，切换为定点（loiter）模式操作，这种模式依靠卫星定位，辅助无人机稳定飞行。 * 结果 大概一周的时间我完成了这架无人机的组装，之前飞过大疆的M100，懂一些基本的操作常识。首次飞行还算顺利，飞了大概10几分钟。第二次起飞可能是因为电量不是很充足，飞了一会自动下降，它这个电量是通过观察电池电压来判断的，没啥经验的我没意识到低电量的问题，强行推油门上升高度，随后因为动力不足直接炸机，检查后还好只烧了一个电机（电机内铜丝发黑，并且有烧焦味），后续换了新的电机，它又重获新生了！ * 结论 这次的无人机组装接触到了很多新知识，为客服的耐心解答点赞。还是有很多收获的，看着这个大家伙挺有成就感的！最后，感受下他的动力吧！（建议调低音量观看！）","categories":[{"name":"无人机","slug":"无人机","permalink":"http://example.com/categories/%E6%97%A0%E4%BA%BA%E6%9C%BA/"}],"tags":[{"name":"pixhawk2.4.8","slug":"pixhawk2-4-8","permalink":"http://example.com/tags/pixhawk2-4-8/"},{"name":"APM","slug":"APM","permalink":"http://example.com/tags/APM/"},{"name":"PX4","slug":"PX4","permalink":"http://example.com/tags/PX4/"},{"name":"电调","slug":"电调","permalink":"http://example.com/tags/%E7%94%B5%E8%B0%83/"},{"name":"DIY无人机","slug":"DIY无人机","permalink":"http://example.com/tags/DIY%E6%97%A0%E4%BA%BA%E6%9C%BA/"}]},{"title":"智能路灯平台灯具控制系统的设计与实现","slug":"智能路灯系统的设计与实现","date":"2021-11-29T03:32:43.000Z","updated":"2021-12-11T13:01:39.020Z","comments":true,"path":"2021/11/29/智能路灯系统的设计与实现/","link":"","permalink":"http://example.com/2021/11/29/%E6%99%BA%E8%83%BD%E8%B7%AF%E7%81%AF%E7%B3%BB%E7%BB%9F%E7%9A%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/","excerpt":"","text":"智能路灯平台灯具控制系统的设计与实现目录12345678910111213141516171819* 摘要 * 研究过程与总体设计: * 关键技术：NB-IOT模块与STM32 MQTT通信协议 * 代码实现： * MQTT服务器的连接：打开 MQTT 客户端网络及连接客户端至 MQTT 服务器。 * 订阅与发布：订阅激活、开\\\\关路灯相关主题；发布反馈结果及状态信息相关主题。 * 硬件看门狗：程序出现死循环时，通过及时喂狗让系统进行复位让系统更加可靠稳定。 * 配置信息存储：FLASH的读写。 * STM32通用定时器：定时上发路灯状态 * 效果展示及系统测试：远程打开/关闭路灯及路灯异常检测 摘要 随着科技社会的不断发展，传统路灯已经不能满足绿色、环保、节能生活的需求。越来越多的照明系统开始通过网络控制平台进行在线管理，实现新时代新理念的智能生活。针对目前节能生活的迫切需求，经过此次项目开发，设计并实现了智能灯具控制系统。 系统利用NB-IoT技术覆盖范围广、连接多、成本低、功耗低的优点，解决了传统路灯系统电力浪费过大、维护成本过高的问题，满足了功能性需求及在可靠性方面的非功能性需求，达到了系统设计目标。 研究过程与总体设计: 关键技术：NB-IOT模块与STM32 MQTT通信协议 效果示意： 详细参考我在CSDN写的博客","categories":[{"name":"单片机","slug":"单片机","permalink":"http://example.com/categories/%E5%8D%95%E7%89%87%E6%9C%BA/"}],"tags":[{"name":"STM32","slug":"STM32","permalink":"http://example.com/tags/STM32/"},{"name":"NB-iot","slug":"NB-iot","permalink":"http://example.com/tags/NB-iot/"},{"name":"智能路灯","slug":"智能路灯","permalink":"http://example.com/tags/%E6%99%BA%E8%83%BD%E8%B7%AF%E7%81%AF/"},{"name":"硬件看门狗","slug":"硬件看门狗","permalink":"http://example.com/tags/%E7%A1%AC%E4%BB%B6%E7%9C%8B%E9%97%A8%E7%8B%97/"},{"name":"MOTT协议","slug":"MOTT协议","permalink":"http://example.com/tags/MOTT%E5%8D%8F%E8%AE%AE/"}]},{"title":"hexo本地预览打开失败：4000端口占用","slug":"hexo-4000端口占用","date":"2021-11-17T07:51:40.000Z","updated":"2021-11-17T08:19:02.494Z","comments":true,"path":"2021/11/17/hexo-4000端口占用/","link":"","permalink":"http://example.com/2021/11/17/hexo-4000%E7%AB%AF%E5%8F%A3%E5%8D%A0%E7%94%A8/","excerpt":"","text":"hexo本地预览打开失败：4000端口占用起因：昨天在发布博客的时候，想着先在本地部署预览一下子。 1hexo g &amp;&amp; hexo s 好家伙直接打不开，着急下班就直接线上部署，这样改一次部署一次，贼麻烦。 经过：今天有空了解决一下，老规矩打开浏览器搜索。 原因：端口占用，查看下占用端口的进程号1netstat -aon|findstr 4000 根据pid查找，对应的应用程序 果然是nxd.exe占用了4000端口 方法：①：修改本地部署的端口：改4000为4001 1hexo server -p 4001 修改后打开本地预览，成了。 ②：杀掉占用的程序： 网上说的cmd 命令貌似对这个nomachine不管用，死了又复活重启也不行。垃圾软件直接卸载，查看4000端口占用，没人占用，再部署。成了！ 杀死进程的命令： 1234//根据进程kill掉对应端口taskkill /f /t /pid 进程号//关闭对应程序taskkill /f /t /im 程序名称(java.exe) 结果：遇到问题，找到原因，解决问题，多尝试！","categories":[{"name":"搭建个人博客","slug":"搭建个人博客","permalink":"http://example.com/categories/%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://example.com/tags/hexo/"},{"name":"端口占用","slug":"端口占用","permalink":"http://example.com/tags/%E7%AB%AF%E5%8F%A3%E5%8D%A0%E7%94%A8/"}]},{"title":"YOLOv4-tiny在jetson NANO\\TX2\\NX下的实时目标检测（从装系统到功能实现）","slug":"YOLOv4-tiny在jetson nano(TX2)下的实时目标检测","date":"2021-11-10T04:42:43.000Z","updated":"2022-02-28T01:23:42.516Z","comments":true,"path":"2021/11/10/YOLOv4-tiny在jetson nano(TX2)下的实时目标检测/","link":"","permalink":"http://example.com/2021/11/10/YOLOv4-tiny%E5%9C%A8jetson%20nano(TX2)%E4%B8%8B%E7%9A%84%E5%AE%9E%E6%97%B6%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/","excerpt":"","text":"YOLOv4-tiny在jetson NANO\\TX2\\NX下的实时目标检测（从装系统到功能实现）* 目的 在nvidia jetson系列的嵌入式平台上,运用YOLOv4-tiny算法以及TensorRT加速框架,实现实时的目标检测. 环境 Jetpack 4.4 CUDA 10.2 ONNX 1.4.1 * 实践* 烧系统 准备系统镜像.img（jetpack4.4:实测nx和nano不通用，用nano的img烧进去nx不识别） 官网下载jetpack4.4. tips:英伟达官网下载有时会很慢：改.com为.cn 准备三大件（提取码：8848）：1、格式化内存卡：SD Card Formatter 2.烧写工具：balenaEtcher 3.备用烧写工具Win32DiskImager。烧写失败时，这两个工具换着用。 格式化卡 * 烧写系统 * 把SD卡插到板子上，开机后初始化下系统就可以“愉快的”配置环境了 * 配环境* CUDA 10.21234打开配置文件sudo gedit ~/.bashrc 12345添加环境变量export PATH=/usr/local/cuda-10.2/bin:$PATHexport LD_LIBRARY_PATH=/usr/local/cuda-10.2/lib64:$LD_LIBRARY_PATH 1234刷新环境变量source ~/.bashrc 查看CUDA版本 * 换源123换源sudo vim /etc/apt/sources.list 123456789101112替换软件源（清华源）deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ xenial-updates main restricted universe multiversedeb-src http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ xenial-updates main restricted universe multiversedeb http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ xenial-security main restricted universe multiversedeb-src http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ xenial-security main restricted universe multiversedeb http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ xenial-backports main restricted universe multiversedeb-src http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ xenial-backports main restricted universe multiversedeb http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ xenial main universe restricteddeb-src http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ xenial main universe restricted 1234567更新软件库sudo apt-get update更新依赖sudo apt-get upgrade 换源cantt find yilai ​ * pip安装及更新 pip安装及更新 123456sudo apt-get install python-pip #python2sudo apt-get install python3-pip #python3sudo apt-get remove python-pipwget https://bootstrap.pypa.io/get-pip.pypython get-pip.pyhash -r pip已经安装，但是/usr/bin/pip: No such file or directory pip: No such file or directory setpool报错 setpool python 版本切换 3.6/2.7 1 删除原有链接 1sudo rm /usr/bin/python 2 建立软连接 1sudo ln -s /usr/bin/python3.6 /usr/bin/python //3.6 3.5 2.7 可以根据需求更改 curl: curl 安装curl时报错 curl : Depends: libcurl3-gnutls (= 7.47.0-1ubuntu2.12) but 7.58.0-2ubuntu3.6 is to be installed 提示安装curl依赖的libcurl版本不一致，这个时候用purge命令重新安装就好了 部署YOLO+TRT 下载源码： 1git clone [https://github.com/jkjung-avt/tensorrt_demos.git](https://github.com/jkjung-avt/tensorrt_demos.git) * 安装onnx模型： 12sudo apt-get install protobuf-compiler libprotoc-devsudo pip3 install onnx==1.4.1 ​​ * 编译下plugins文件夹里的相关文件 1make * 转换yolo文件 * 1.将.weight模型文件转换成 .onnx 格式 1python3 yolo_to_onnx.py -m yolov4-tiny-416 * 2.再将 .onnx文件转换成 .trt 格式 1python3 onnx_to_tensorrt.py -m yolov4-tiny-416 * 3.启用摄像头实时检测 1python3 trt_yolo.py --usb 0 -m yolov4-tiny-416 ​ 结果 实时检测帧数在40左右，下一篇接着总结NMS、精准度等调参问题 结论 网上的教程鱼龙混杂，推荐一篇不错的博文。起初在nano上部署成功，后来尝试按照自己总结的这套方法在NX上复现。没有啥大问题的话，不到一个小时环境部署就可以完成，祝你好运！","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"YOLO","slug":"深度学习/YOLO","permalink":"http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/YOLO/"},{"name":"Nvidia","slug":"深度学习/YOLO/Nvidia","permalink":"http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/YOLO/Nvidia/"}],"tags":[{"name":"YOLO","slug":"YOLO","permalink":"http://example.com/tags/YOLO/"},{"name":"实时目标识别检测","slug":"实时目标识别检测","permalink":"http://example.com/tags/%E5%AE%9E%E6%97%B6%E7%9B%AE%E6%A0%87%E8%AF%86%E5%88%AB%E6%A3%80%E6%B5%8B/"},{"name":"jetson nano","slug":"jetson-nano","permalink":"http://example.com/tags/jetson-nano/"},{"name":"onnx","slug":"onnx","permalink":"http://example.com/tags/onnx/"},{"name":"tensorRT","slug":"tensorRT","permalink":"http://example.com/tags/tensorRT/"}]},{"title":"添加gitalk博客评价插件","slug":"添加gitalk插件","date":"2021-11-05T00:51:40.000Z","updated":"2021-11-05T04:43:58.252Z","comments":true,"path":"2021/11/05/添加gitalk插件/","link":"","permalink":"http://example.com/2021/11/05/%E6%B7%BB%E5%8A%A0gitalk%E6%8F%92%E4%BB%B6/","excerpt":"","text":"添加gitalk博客评价插件前提：1.使用hexo+github搭建的个人博客2.没有绑定域名直接上方法：1.创建存储评论的GitHub仓库 2.初始化这个仓库在setting里勾选issues选项 创建一条issue 3.github注册应用注册applicantion 注册后生成的id、密码填到配置文件里 4.修改主题的_config.yml文件，部署并预览修改主题的配置文件 部署一下 随便打开一个博客看下 点一下初始化issue,成了！","categories":[{"name":"搭建个人博客","slug":"搭建个人博客","permalink":"http://example.com/categories/%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://example.com/tags/hexo/"},{"name":"Fluid","slug":"Fluid","permalink":"http://example.com/tags/Fluid/"},{"name":"gitalk","slug":"gitalk","permalink":"http://example.com/tags/gitalk/"}]},{"title":"极本穷源：ROS篇","slug":"ROS基础学习","date":"2021-11-03T00:51:40.000Z","updated":"2021-12-06T07:05:31.644Z","comments":true,"path":"2021/11/03/ROS基础学习/","link":"","permalink":"http://example.com/2021/11/03/ROS%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"ROS入门ROS（Robot Operating System）机器人操作系统本文素材来自古月ROS入门21讲，正在总结归纳，择日上传！ * 概念 * 发展 * 应用 * 通信机制 * 开发工具 * 功能开发 * ROS生态系统 * ROS节点实现：SLAM（同步定位与地图构建）（C++）、A* Dijkstra（最短路径规划）、YOLO（目标识别检测）（python） 单片机 Arduino MCU 主频 Mb，PC、 树莓派、jetson系列 主频 Gb * 一个典型的ROS机器人Turtlebot：激光雷达（360°深度信息，SLAM导航）、树莓派（应用层：ROS功能包功能实现SLAM等）、OpenCR（底层运动处理，电机PID闭环控制，传感器采集..）","categories":[{"name":"极本穷源","slug":"极本穷源","permalink":"http://example.com/categories/%E6%9E%81%E6%9C%AC%E7%A9%B7%E6%BA%90/"}],"tags":[{"name":"古月居","slug":"古月居","permalink":"http://example.com/tags/%E5%8F%A4%E6%9C%88%E5%B1%85/"},{"name":"机器人","slug":"机器人","permalink":"http://example.com/tags/%E6%9C%BA%E5%99%A8%E4%BA%BA/"},{"name":"ROS基础","slug":"ROS基础","permalink":"http://example.com/tags/ROS%E5%9F%BA%E7%A1%80/"},{"name":"ROS节点","slug":"ROS节点","permalink":"http://example.com/tags/ROS%E8%8A%82%E7%82%B9/"}]},{"title":"简述通信协议栈和计算机网络的OSI模型","slug":"简述通信协议栈和计算机网络的OSI模型","date":"2021-10-28T02:07:06.000Z","updated":"2021-12-16T08:07:49.804Z","comments":true,"path":"2021/10/28/简述通信协议栈和计算机网络的OSI模型/","link":"","permalink":"http://example.com/2021/10/28/%E7%AE%80%E8%BF%B0%E9%80%9A%E4%BF%A1%E5%8D%8F%E8%AE%AE%E6%A0%88%E5%92%8C%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%9A%84OSI%E6%A8%A1%E5%9E%8B/","excerpt":"","text":"简述通信协议栈和计算机网络的OSI模型 前段时间买了套无人机的通信控制模块，某宝上写的是开源，结果到手来了个只开源应用层（配套的应用软件）。我们需要的是网络层开源支持（与无人机直接通信的模块固件源码），只有拿到这部分代码才能把无人机载荷采集到的有用信息有效发挥，比如直接根据传感器信息控制无人机的自主飞行亦或是将载荷信息通过该通信链路传输到地面站，甚至可以是无人机结点间的信息交互，总之这份“价值超过500W源码”是不肯开源的。 被人怼就要吸取教训，今天就来学习总结下什么是通信协议栈，什么是计算机网络的OSI模型 通信协议栈： 简单来说就是一种网络通信协议的堆叠，网络协议就是通信双方约定好的通信规则。 协议栈的应运而生：数据在网络中的传输（寻址、抗干扰、加密、数据分割、压缩等）是极其复杂的。使用单一协议无法保障数据高速准确的传输，单一协议会导致协议冗余、复杂、难以优化，因此通过各层协议各司其职，互相配合使得通信效率更加高效。 通俗的打个比方：老板要下发一个工作通知到张三，（假设该协议栈只有两层：聊天层和纠错层）聊天层采用“通知内容转换协议” 把 “明天不上班” 这条消息转换为二进制的计算机信息：“01”，“01” 这条消息被传输到纠错层后采用 “信息无误就是1协议” 为 “01” 增加标志 “1或0”表示这条信息是否因受到网络传输干扰产生误差。那么张三有效收到“明天不上班”这条通知的二进制计算机信息就是“101”，这就是一个简单协议栈的基本原理。 比较常见的 TCP/IP 协议栈： TCP/IP 协议栈有四层结构：应用层、传输层、网络层、链路层。 深入浅出 TCP/IP 协议栈 - 一像素 - 博客园 (cnblogs.com) 链路层：将特定意义的数据（“明天上班”）加帧头、加帧尾构成一个数据包（数据帧），以广播的形式通过物理介质发送给接收方。以太网协议规定一组电信号就是一个数据包，一个数据包叫做一帧。帧头包含了目标MAC地址、源MAC地址和类型（大小为46-1500字节），以太网规协议又规定通信双方的网络设备必须安装有独一无二标识的网络适配器（这个标识就是网卡地址、数据包的发送地址和接收地址、也是帧头的MAC地址），帧尾提供校验数据是否损坏的校验序列； 协议数据单元在应用层、表示层和会话层被称做数据(Data)，在传输层被称做分段(Segment)，在网络层被称做包(Packet)，在数据链路层被称做帧(Frame)，在物理层被称做比特(Bit)。 网络层：定义IP地址，确认主机所在的网络位置，并通过IP进行MAC寻址，对外网数据包进行路由转发； 传输层：定义端口，确认主机上应用程序的身份，并将数据包交给对应的应用程序； 应用层：定义数据格式，并按照对应的格式解读数据。 计算机网络的OSI模型 怎么来的OSI模型：说是有一群叫做国际标准化组织的人（ISO），试图为全世界互联的各种计算机制定一套网络标准框架。框架和模型：框架是处理流程，模型是描述问题的工具。OSI（开放式系统互联通信参考模型）就是这个框架下的一种模型。 计算机网络 OSI网络模型 - 知乎 (zhihu.com) 简述七层OSI模型：物理层—&gt;二进制比特流与光电信号的互相转换；数据链路层—&gt;互连的网络设备之间的帧识别与帧传输；网络层—&gt;同一子网的寻址，不同子网的路由转发；传输层—&gt;建立端对端的通信，确保通信的稳定；会话层—&gt;建立和断开通信连接，同步会话等；表示层—&gt;数据的转换（格式，加密和压缩），数据传输的承上启下；应用层—&gt;为用户使用的应用程序提供网络服务，建立数据传输连接。 (3条消息) 网络通讯基础（一）OSI七层模型和TCP/IP四层（五层）模型_mxxrgxg的博客-CSDN博客 七层OSI 与 四层TCP/IP 模型的对比 TCP/IP的四层模型与OSI七层模型的有什么不同？","categories":[{"name":"计算机网络","slug":"计算机网络","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"}],"tags":[{"name":"协议栈","slug":"协议栈","permalink":"http://example.com/tags/%E5%8D%8F%E8%AE%AE%E6%A0%88/"},{"name":"TCP/IP协议栈","slug":"TCP-IP协议栈","permalink":"http://example.com/tags/TCP-IP%E5%8D%8F%E8%AE%AE%E6%A0%88/"},{"name":"OSI模型","slug":"OSI模型","permalink":"http://example.com/tags/OSI%E6%A8%A1%E5%9E%8B/"},{"name":"TCP/IP模型","slug":"TCP-IP模型","permalink":"http://example.com/tags/TCP-IP%E6%A8%A1%E5%9E%8B/"}]},{"title":"YOLOv3在ubuntu20.04下训练自己的数据集(从“零”开始)","slug":"YOLOv3在ubuntu20.04下训练自己的数据集","date":"2021-10-24T01:17:55.000Z","updated":"2022-02-09T01:35:50.104Z","comments":true,"path":"2021/10/24/YOLOv3在ubuntu20.04下训练自己的数据集/","link":"","permalink":"http://example.com/2021/10/24/YOLOv3%E5%9C%A8ubuntu20.04%E4%B8%8B%E8%AE%AD%E7%BB%83%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86/","excerpt":"","text":"YOLOv3在ubuntu20.04下训练自己的数据集 背景基础 实现了在win10及树莓派4B下yolov3的配置及使用 目的 使用Ubuntu20.04下的yolov3 v4 对自己的数据集进行训练 将训练好的权重文件移植到机载树莓派上实现嵌入式系统实时的目标检测 利用机载树莓派实时的目标检测信息，将该点位置信息发送至感知无人机进行协作，同时将检测结果发送至地面站进行反馈 方法 darknet-yolov3训练自己的数据集（超详细） - AnswerThe - 博客园 (cnblogs.com) 准备工作 Ubuntu20.04的安装（这里选择双系统安装） (1条消息) win10+ubuntu双系统配置_CUG_UESTC的博客-CSDN博客 下载镜像：清华大学开源软件镜像站 | Tsinghua Open Source Mirror 制作启动盘 (1条消息) 用UltraISO制作Ubuntu16.04 U盘启动盘_YaoyuT的博客-CSDN博客 ubuntu20.04镜像百度网盘链接提取码：dslz 磁盘分配100G（102400MB）空间给ubuntu 遇到的坑 刚买的新机器装不上旧版本的（18.04和16.04）Ubuntu（电脑配置11代8核i7-1180H 16G 512GSSD RTX3050），旧的台式机试过没问题 128G的大U盘在制作启动盘时需要将U盘格式为FAT32，写入镜像后不能正常安装，换个小容量U盘解决 设置电脑BIOS,很多新机器·默认uefi启动模式，在boot里并没有这个模式切换选项，但是有一个关闭UEFI的选项，关闭后就可切换到Legacy启动，一般来说开机按F12进入到图三的界面时有UEFI：的U盘时就是正确的引导模式 环境安装 cuda11.4+cudnn11.4 (1条消息) ubuntu16.04+cuda8.0+cudnn5.1详细安装过程_weixin_43878078的博客-CSDN博客 (1条消息) Ubuntu18.04下复现YOLOv4（YOLOv3亦可）_hesongzefairy的博客-CSDN博客​ 下载cuda,终端输入： 1wget https://developer.download.nvidia.com/compute/cuda/11.4.1/local_installers/cuda_11.4.1_470.57.02_linux.run 安装： 1sudo sh cuda\\_11.4.1\\_470.57.02_linux.run 设置环境变量： 1sudo gedit ~/.bashrc 打开配置文件并在末尾加上： 12export PATH=/usr/local/cuda-8.0/bin$&#123;PATH:+:$&#123;PATH&#125;&#125;export LD\\_LIBRARY\\_PATH=/usr/local/cuda-8.0/lib64$&#123;LD\\_LIBRARY\\_PATH:+:$&#123;LD\\_LIBRARY\\_PATH&#125;&#125; 按如下步骤进行： 测试CUDA安装成了没： 1nvcc -V 下载cudnn 下载官网匹配版本 opencv4.5.0:教程中的图文对应OPENCV版本号有问题，方法都一样 (1条消息) Ubuntu20.04 配置Yolov4(gpu版，安装OpenCV，配置环境)_小菜彭-没拿过奖学金的废物的博客的博客-CSDN博客 训练数据 darknet-yolov3训练自己的数据集（超详细） - AnswerThe - 博客园 (cnblogs.com) 数据集可以用之前在Windows下标注的数据集，将之前标注好的图片和xml文件放到对应目录下。 在myData目录下创建test.py 12345678910111213141516171819202122232425262728293031import osimport randomtrainval_percent = 0.1train_percent = 0.9xmlfilepath = &#x27;Annotations&#x27;txtsavepath = &#x27;ImageSets\\Main&#x27;total_xml = os.listdir(xmlfilepath)num = len(total_xml)list = range(num)tv = int(num * trainval_percent)tr = int(tv * train_percent)trainval = random.sample(list, tv)train = random.sample(trainval, tr)ftrainval = open(&#x27;ImageSets/Main/trainval.txt&#x27;, &#x27;w&#x27;)ftest = open(&#x27;ImageSets/Main/test.txt&#x27;, &#x27;w&#x27;)ftrain = open(&#x27;ImageSets/Main/train.txt&#x27;, &#x27;w&#x27;)fval = open(&#x27;ImageSets/Main/val.txt&#x27;, &#x27;w&#x27;)for i in list: name = total_xml[i][:-4] + &#x27;\\n&#x27; if i in trainval: ftrainval.write(name) if i in train: ftest.write(name) else: fval.write(name) else: ftrain.write(name)ftrainval.close()ftrain.close()fval.close()ftest.close() 运行test.py生成对应的四个txt文件运行 用python脚本将数据集进行格式转换（YOLO 训练需要的格式），在darknet文件夹下新建一个my_lables.py文件(代码如下),运行后生成代表类别和相对位置的myData_train.txt，以及lables文件夹下的txt文件 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647import xml.etree.ElementTree as ETimport pickleimport osfrom os import listdir, getcwdfrom os.path import join #源代码sets=[(&#x27;2012&#x27;, &#x27;train&#x27;), (&#x27;2012&#x27;, &#x27;val&#x27;), (&#x27;2007&#x27;, &#x27;train&#x27;), (&#x27;2007&#x27;, &#x27;val&#x27;), (&#x27;2007&#x27;, &#x27;test&#x27;)]sets=[(&#x27;myData&#x27;, &#x27;train&#x27;)] # 改成自己建立的myDataclasses = [&quot;people&quot;] # 改成自己的类别def convert(size, box): dw = 1./(size[0]) dh = 1./(size[1]) x = (box[0] + box[1])/2.0 - 1 y = (box[2] + box[3])/2.0 - 1 w = box[1] - box[0] h = box[3] - box[2] x = x*dw w = w*dw y = y*dh h = h*dh return (x,y,w,h)def convert_annotation(year, image_id): in_file = open(&#x27;myData/Annotations/%s.xml&#x27;%(image_id)) # 源代码VOCdevkit/VOC%s/Annotations/%s.xml out_file = open(&#x27;myData/labels/%s.txt&#x27;%(image_id), &#x27;w&#x27;) # 源代码VOCdevkit/VOC%s/labels/%s.txt tree=ET.parse(in_file) root = tree.getroot() size = root.find(&#x27;size&#x27;) w = int(size.find(&#x27;width&#x27;).text) h = int(size.find(&#x27;height&#x27;).text) for obj in root.iter(&#x27;object&#x27;): difficult = obj.find(&#x27;difficult&#x27;).text cls = obj.find(&#x27;name&#x27;).text if cls not in classes or int(difficult)==1: continue cls_id = classes.index(cls) xmlbox = obj.find(&#x27;bndbox&#x27;) b = (float(xmlbox.find(&#x27;xmin&#x27;).text), float(xmlbox.find(&#x27;xmax&#x27;).text), float(xmlbox.find(&#x27;ymin&#x27;).text), float(xmlbox.find(&#x27;ymax&#x27;).text)) bb = convert((w,h), b) out_file.write(str(cls_id) + &quot; &quot; + &quot; &quot;.join([str(a) for a in bb]) + &#x27;\\n&#x27;)wd = getcwd()for year, image_set in sets: if not os.path.exists(&#x27;myData/labels/&#x27;): # 改成自己建立的myData os.makedirs(&#x27;myData/labels/&#x27;) image_ids = open(&#x27;myData/ImageSets/Main/%s.txt&#x27;%(image_set)).read().strip().split() list_file = open(&#x27;myData/%s_%s.txt&#x27;%(year, image_set), &#x27;w&#x27;) for image_id in image_ids: list_file.write(&#x27;%s/myData/JPEGImages/%s.jpg\\n&#x27;%(wd, image_id)) convert_annotation(year, image_id) list_file.close() 打开自己的cfg文件如图按照自己电脑配置修改训练批次和训练迭代次数。 据实际情况分别修改三处classes（每个[yolo]下）,filters=(classes + 5)x3(每个[yolo]上的第一个[convolutional])。 修改cfg/my_data.data 新建myData.names 下载预训练权重，网上找个拷贝进去 预训练权重链接: https://pan.baidu.com/s/10HPZsmBP8mpU0HcHLgSk-Q 提取码: 76fq 开始训练： 1./darknet detector train cfg/my\\_data.data cfg/my\\_yolov3.cfg darknet53.conv.74 从停止处重新训练： 1./darknet detector train cfg/my\\_data.data cfg/my\\_yolov3.cfg darknet53.conv.74 -gups 0,1,2,3 myData/weights/my_yolov3.backup -gpus 0,1,2,3 结果分析 纵坐标平均loss（误差）接近0.0359，即变化不大时可停止训练。横坐标batch（每batch（64）个样本更新一次参数） 当前训练的迭代次数: 6478,总体的 Loss(损失）:0.0279,平均 Loss:0.0359 测试效果： 1./darknet detect cfg/my\\_yolov3.cfg weights/my\\_yolov3.weights 72.jpg","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"YOLO","slug":"深度学习/YOLO","permalink":"http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/YOLO/"},{"name":"Ubuntu","slug":"深度学习/YOLO/Ubuntu","permalink":"http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/YOLO/Ubuntu/"}],"tags":[{"name":"YOLO","slug":"YOLO","permalink":"http://example.com/tags/YOLO/"},{"name":"目标识别检测","slug":"目标识别检测","permalink":"http://example.com/tags/%E7%9B%AE%E6%A0%87%E8%AF%86%E5%88%AB%E6%A3%80%E6%B5%8B/"},{"name":"训练数据集","slug":"训练数据集","permalink":"http://example.com/tags/%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E9%9B%86/"}]},{"title":"极本穷源：YOLO篇（篇幅过长，整理后择日上传）","slug":"YOLO基础学习","date":"2021-10-23T07:42:43.000Z","updated":"2021-12-16T08:14:46.195Z","comments":true,"path":"2021/10/23/YOLO基础学习/","link":"","permalink":"http://example.com/2021/10/23/YOLO%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0/","excerpt":"","text":"YOLO 基础学习YOLOV3的网络架构卷积 池化 连接 上下采样 什么是卷积？学过高等数学的对这个词都不陌生，具体参考马同学讲的。 从数学上来讲“卷积”就是一种数学运算， 什么是图像的上下采样？ 缩小图像（或称为下采样（subsampled）或降采样（downsampled））的主要目的有两个：1、使得图像符合显示区域的大小；2、生成对应图像的缩略图。 放大图像（或称为上采样（upsampling）或图像插值（interpolating））的主要目的是放大原图像,从而可以显示在更高分辨率的显示设备上。 对图像的缩放操作并不能带来更多关于该图像的信息, 因此图像的质量将不可避免地受到影响。然而，确实有一些缩放方法能够增加图像的信息，从而使得缩放后的图像质量超过原图质量的。 YOLO 和 Tiny YOLO 的关系* AI”炼丹”是啥 深度学习训练模型就像炼丹，没啥理论，纯靠实验，要有很多设备，动不动的训练好几天的数据 * 机器学习算法工程师都要干些啥 1.基于提出需求设计组合算法即策略解决问题，不限于深度学习，传统视觉，算法策略，大部分需求都是组合算法解决的，例如检测分类姿态等多模态模型组合并配合一些传统算法解决问题(pytorch/caffe opencv) 2.训练数据采集方案的设计，标注规则的指定以及数据审核 3.快速实现算法demo并验证算法逻辑策略部分以及评估自测(Python) 4.模型实际部署平台的性能资源占用和效率评估，评估ok走下一步，否则返回3步骤针对优化验证， 5.基于c/c++完成算法sdk库开发，其中涉及到模型多平台移植部署(涉及到后端nn推理框架的选用，前后处理部分代码的编写)，代码高性能优化(simd cuda openc,openmpl...) 6.算法库文档编写，外发sdk库 * yolov3基础知识* 上采样，下采样##NMS是啥，如何进行NMS调参## NMS（）：非极大化抑制算法。 * 288.cfg ignore_thresh = .7 beta_nms=0.7 result * 288.cfg ignore_thresh = .7 beta_nms=0.8 result * 416.cfg ignore_thresh = .7 beta_nms=0.7 result * 416.cfg ignore_thresh = .7 beta_nms=0.5 result","categories":[{"name":"极本穷源","slug":"极本穷源","permalink":"http://example.com/categories/%E6%9E%81%E6%9C%AC%E7%A9%B7%E6%BA%90/"}],"tags":[{"name":"YOLO","slug":"YOLO","permalink":"http://example.com/tags/YOLO/"},{"name":"卷积","slug":"卷积","permalink":"http://example.com/tags/%E5%8D%B7%E7%A7%AF/"},{"name":"池化","slug":"池化","permalink":"http://example.com/tags/%E6%B1%A0%E5%8C%96/"},{"name":"连接","slug":"连接","permalink":"http://example.com/tags/%E8%BF%9E%E6%8E%A5/"},{"name":"上下采样","slug":"上下采样","permalink":"http://example.com/tags/%E4%B8%8A%E4%B8%8B%E9%87%87%E6%A0%B7/"}]},{"title":"不花一分钱搭建个人博客","slug":"不花一分钱搭建个人博客","date":"2021-10-22T06:08:00.000Z","updated":"2021-10-25T01:27:26.548Z","comments":true,"path":"2021/10/22/不花一分钱搭建个人博客/","link":"","permalink":"http://example.com/2021/10/22/%E4%B8%8D%E8%8A%B1%E4%B8%80%E5%88%86%E9%92%B1%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/","excerpt":"","text":"不花一分钱搭建个人博客，有手就行起因 前段时间在网上找代码，看到一位大佬的个人博客。 看到网址后缀有github，对新鲜事物充满好奇又有动手能力的我。遇到这种情况怎么说，当然是打开CSDN 搜索关键字github.io。果然一大堆教程，又了解到一个用 Node.js 构建的快速、简洁且强大的博客框架:Hexo 。最初由Tommy Chen于2012年创建和维护。从那时起，它帮助成千上万的人建立了他们的梦想网站/博客。 上手 目的 那么如何基于github和Hexo搭建个人博客呢 (3条消息) 搭建GitHub免费个人网站（详细教程）_苍何的博客-CSDN博客_用github搭建个人网站 方法 注册gtihub 安装node.js 安装并配置git 安装hexo并新建GitHub仓库 修改主题，网上搜hexo主题选择自己喜欢的风格 感受下大家的魔改版 云游君的小站 (yunyoujun.cn) 小白妹妹写代码 部署好模板后，问题又来了：怎么写博客 这里介绍下我自己的方法，在\\hexo\\source_posts目录下，新建.md的博客 内容格式如图，其中tag为标签，categories为分类 OK，现在模板有了，博客内容也有了。问题又来了：网站加载速度有时候特别慢，那咋办嘛 * 用自己的服务器搭建的，可以试下CDN加速 * 换下图片存储的位置，网上有很多免费的图片托管网站，但是一张一张的存太麻烦了 * * 直接存到幕布上，导出HTML文件，转为.md文件，复制想要的内容到自己的博客中，适当修改下格式，大功告成。 结果 我选一款比较简洁的模板，欢迎来访。，增加了页脚网站运行时间、不蒜子网页访问统计等功能 结论 前后尝试试过几种模板，配置起来都不算难。遇到问题先百度下，祝你好运。","categories":[{"name":"搭建个人博客","slug":"搭建个人博客","permalink":"http://example.com/categories/%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://example.com/tags/hexo/"},{"name":"markdown","slug":"markdown","permalink":"http://example.com/tags/markdown/"}],"author":"Ethan"},{"title":"YOLO算法在windows下训练自己的数据集","slug":"YOLO算法在windows下训练自己的数据集","date":"2021-10-21T11:20:00.000Z","updated":"2022-02-09T01:35:27.487Z","comments":true,"path":"2021/10/21/YOLO算法在windows下训练自己的数据集/","link":"","permalink":"http://example.com/2021/10/21/YOLO%E7%AE%97%E6%B3%95%E5%9C%A8windows%E4%B8%8B%E8%AE%AD%E7%BB%83%E8%87%AA%E5%B7%B1%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86/","excerpt":"","text":"YOLO算法在windows下训练自己的数据集背景基础 已有在官方权重下，YOLOV3算法在识别物体上的测试效果 特定数据集的制作与训练实现特有的目标检测 目的xx目标的识别检测 方法(1条消息) win10下yolov3训练自己的数据集_congcong7267的博客-CSDN博客 训练自己的数据集、* 每种物体采集大概两三百张照片（距离、背景、光线） * 标注图片中的目标，制作数据集 * 打开win10终端，cd进入darknet-master\\\\build\\\\darknet\\\\x64，darknet.exe detector train data/obj.data yolo-obj.cfg darknet53.conv.74 开始训练 生成权重文件移植到树莓派上进行测试* backup文件下最后一个权重文件复制到build\\\\darknet\\\\x64\\ * 打开win10终端，cd进入然后运行darknet-master\\\\build\\\\darknet\\\\x64路径 * 输入：darknet.exe detector test data/obj.data yolo-obj.cfg yolo-obj\\_100.weights（olo-obj\\_100.weights为训练好的权重名） * 终端会提醒你输入图片路径，然后你输入测试图片的绝对路径即可看到效果 实践(2条消息) win10下yolov3训练自己的数据集_congcong7267的博客-CSDN博客 新建yolo-obj.cfg文件，将batch 改成64 ：batch=64，subdivisions=64在Darknet中，batch和subdivisions是结合使用的，例如设置batch=64，subdivisions=16，表示训练的过程中将一次性加载64张图片进内存，然后分16次完成前向传播，意思是每次4张，前向传播的循环过程中累加loss求平均，待64张图片都完成前向传播后，再一次性后传更新参数。(yolov3.cfg参数说明及调参经验 - 知乎 (zhihu.com)) 接着根据训练类别数（classes），修改每个[yolo]（三处）上面（即每个yolo的输出层）的第一个convolution里filters（滤波器）的大小 filters=(classes + 5)x3，每个[yolo]（三处）下面 的classes修改为自己的类别数。 在build\\darknet\\x64\\data\\下新建obj.names文件，写入自己的类名 在build\\darknet\\x64\\data\\下新建obj.data文件 制作数据集 图片批量顺序命名py脚本 使用labelimg标注图片中的目标，生成xml文件 使用py脚本将xml文件转为txt文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748import osimport xml.etree.ElementTree as ETdirpath = r&#x27;E:\\gongzuo\\伪代码\\darknet\\build\\darknet\\x64\\data\\txt&#x27; # 原来存放xml文件的目录newdir = r&#x27;E:\\gongzuo\\伪代码\\darknet\\build\\darknet\\x64\\data\\obj&#x27; # 修改label后形成的txt目录if not os.path.exists(newdir): os.makedirs(newdir)dict_info = &#123;&#x27;person&#x27;: 0&#125; # 有几个 属性 填写几个label namesfor fp in os.listdir(dirpath): if fp.endswith(&#x27;.xml&#x27;): root = ET.parse(os.path.join(dirpath, fp)).getroot() xmin, ymin, xmax, ymax = 0, 0, 0, 0 sz = root.find(&#x27;size&#x27;) width = float(sz[0].text) height = float(sz[1].text) filename = root.find(&#x27;filename&#x27;).text for child in root.findall(&#x27;object&#x27;): # 找到图片中的所有框 sub = child.find(&#x27;bndbox&#x27;) # 找到框的标注值并进行读取 label = child.find(&#x27;name&#x27;).text label_ = dict_info.get(label) if label_: label_ = label_ else: label_ = 0 xmin = float(sub[0].text) ymin = float(sub[1].text) xmax = float(sub[2].text) ymax = float(sub[3].text) try: # 转换成yolov3的标签格式，需要归一化到（0-1）的范围内 x_center = (xmin + xmax) / (2 * width) x_center = &#x27;%.6f&#x27; % x_center y_center = (ymin + ymax) / (2 * height) y_center = &#x27;%.6f&#x27; % y_center w = (xmax - xmin) / width w = &#x27;%.6f&#x27; % w h = (ymax - ymin) / height h = &#x27;%.6f&#x27; % h except ZeroDivisionError: print(filename, &#x27;的 width有问题&#x27;) with open(os.path.join(newdir, fp.split(&#x27;.xml&#x27;)[0] + &#x27;.txt&#x27;), &#x27;a+&#x27;) as f: f.write(&#x27; &#x27;.join([str(label_), str(x_center), str(y_center), str(w), str(h) + &#x27;\\n&#x27;]))print(&#x27;ok&#x27;) 将所有样本图片及对应的的txt文件)放到：build\\darknet\\x64\\data\\obj\\ 在build\\darknet\\x64\\data\\下新建train.txt，训练图片的路径放入文件 将darknet的预训练权重放入build\\darknet\\x64 预训练权重文件 密码：x5ht 在\\darknet路径下修改网络配置文件Makefile 对比官方makefile修改：（其中C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.4/ 为自己的CUDA安装路径） （下载链接 提取码：jh1i）） * GPU=1 CUDNN=1 * NVCC=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.4/bin/nvcc * COMMON+= -DGPU -I/C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.4/include * LDFLAGS+= -L/C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.4/lib -lcuda -lcudart -lcublas -lcurand ​​ * 打开cmd，cd进入darknet-master\\build\\darknet\\x64路径，输入：darknet.exe detector train data/obj.data yolo-obj.cfg darknet53.conv.74 开始训练 * avg loss接近0.XX且变化不大时可停止训练，将x64\\\\backup下的weight文件复制到\\\\x64下，cd进入darknet-master\\\\build\\\\darknet\\\\x64路径运行darknet.exe detector test data/obj.data yolo-obj.cfg yolo-obj_last.weights，程序会提示输入待检测图片的路径。 结果 纵坐标平均loss（误差）接近0.545，即变化不大时可停止训练。横坐标batch（每batch（64）个样本更新一次参数） 在YOLOv3中，Loss分为三个部分: 1、一个是x、y、w、h部分带来的误差，也就是bbox带来的loss 2、一个是置信度带来的误差，也就是obj带来的loss 3、最后一个是类别带来的误差，也就是class带来的loss 对比使用官方权重与自己训练的数据集检测目标时，由于检测结果受到样本数量的影响两者检测结果均不为理想。 avg loss（误差）接近0.219时，基本不再变化 ####检测结果 #### 参数分析： * 1623： 当前训练的迭代次数; * 0.215670： 总体的 Loss(损失）; * 0.232835 avg： 平均 Loss, 这个数值应该越低越好, 一般来说, 一旦这个数值低于 0.060730 avg 就可以终止训练了; * 0.001000 rate： 当前的学习率, 在.cfg文件中定义的; * 9.07000 seconds： 当前批次训练花费的总时间; * 103875 images： 这一行最后的这个数值是 9798*64 的大小, 表示到目前为止, 参与训练的图片的总量.","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"YOLO","slug":"深度学习/YOLO","permalink":"http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/YOLO/"},{"name":"windos","slug":"深度学习/YOLO/windos","permalink":"http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/YOLO/windos/"}],"tags":[{"name":"YOLO","slug":"YOLO","permalink":"http://example.com/tags/YOLO/"},{"name":"目标识别检测","slug":"目标识别检测","permalink":"http://example.com/tags/%E7%9B%AE%E6%A0%87%E8%AF%86%E5%88%AB%E6%A3%80%E6%B5%8B/"},{"name":"训练数据集","slug":"训练数据集","permalink":"http://example.com/tags/%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E9%9B%86/"}],"author":"Ethan"},{"title":"基于YOLO的目标识别检测","slug":"基于YOLO的目标识别检测","date":"2021-10-21T10:04:50.000Z","updated":"2022-02-09T01:35:06.696Z","comments":true,"path":"2021/10/21/基于YOLO的目标识别检测/","link":"","permalink":"http://example.com/2021/10/21/%E5%9F%BA%E4%BA%8EYOLO%E7%9A%84%E7%9B%AE%E6%A0%87%E8%AF%86%E5%88%AB%E6%A3%80%E6%B5%8B/","excerpt":"","text":"基于YOLO的目标识别检测性能目标： * 目标识别准确率大于90% * 机载相机的有效地空检测距离大于10米 * 所选取相机能实现自主或结合机载电脑实时处理目标识别 感受下基于树莓派的YOLO目标检测算法（可见光）： 独家 | 在树莓派+Movidius NCS上运用YOLO和Tiny-YOLO完成目标检测（附代码下载）_数据派THU-CSDN博客 在树莓派4使用YOLO v3 Tiny进行实时对象检测_weixin_43878078的博客-CSDN博客_树莓派yolo目标检测 方法论证与实践(1条消息) 在树莓派4使用YOLO v3 Tiny进行实时对象检测_weixin_43878078的博客-CSDN博客_树莓派yolo目标检测 YOLO算法在树莓派3B+、4B上实现 步骤 准备Python和Pi相机 安装 Ninja Building tool（控制编译的工具，它相对于Makefile这套工具更注重于编译速度） 安装修改后的 NNPACK（加速神经网络计算的加速包，NNPACK可以在多核CPU平台上提高卷积层计算性能） 安装darknet-nnpack（目的是给树莓派配置yolo模型，Darknet是一个小众的深度学习框架） 存在问题 安装完成，使用树莓派摄像头进行测试。从摄像头获取图像，通过YOLO算法实时的识别物体类别，使用usb摄像头会比CSI（Camera Serial Interface）接口的摄像头慢很多。无法识别摄像头，原因可能是： ①摄像头硬件有问题 ②树莓派上的摄像头驱动等存在问题 YOLOV3在Windows10（OpenCV3.4+CUDA11.4（CUDNN）+VisualStudio2017）下的实现(1条消息) Windows10+YOLOV3+VisualStudio2017最新版本超详细过程_【秋名鱼酱的博客】-CSDN博客_win yolov3 步骤 安装最新版本的cuda和cudnn（CUDA是NVIDIA推出的用于自家GPU的并行计算框架，CUDNN是NVIDIA打造的针对深度神经网络的加速库，是一个用于深层神经网络的GPU加速库） 安装OpenCV3.4（通过OpenCV调用dll实时检测） 安装vs2017（使用本身2017对YOLOV3中的darknet项目文件进行编译） 测试 在测试效果之前还需要添加以下官网上下载训练好的权重文件 权重文件保存的就是训练好的网络各层的权值，也就是通过训练集训练出来的。训练好之后，应用时只要加载权值就可以，不再需要训练集了 输入检测程序命令，实现对JPG、avi文件以及调用摄像头的实时目标检测 实验结果使用官方提供的权重文件检测对一下目标进行检测 视频检测视频检测效果 制作训练集 YOLO有自己训练好的数据集，在YOLO v2 中，数据集可检测的类别达9000种以上，但是9000毕竟不是全部，它能涵盖大部分的物体识别，但是可能对于某些用户来说是不够的，所以我们需要学习它的数据集制作方法。 数据集分为以下几个部分： 1.数据集的搜集，这一部分主要是在网上搜集整理相关数据集的图片，比如我要做某种猫的数据集，我需要上网上查找这种猫的图片；我需要做自己做的手工艺品的数据集，那我需要自己拍摄等等。 2.数据集的标注，计算机去认识一个物体，需要人去告诉他，哪个物体，是什么。就像我们在小时候，我们的父母会一点一点耐心教我们，什么是桌子，什么是椅子，什么是筷子，什么是树，什么是花……数据集的标注就是一个“教授”的过程。 3.数据集的训练，不是别人一教，你就能学会的，你需要不断地练习，比如说话，小时候父母不厌其烦的教我们；比如写汉字，中国人最应该骄傲的就是我们学会了世界上最难的一门语言，并且能够熟练应用。这就是因为我们从上学开始，老师就教我们写字，一写就是好几十遍……计算机也是如此，想让计算机明白什么是花，什么是自行车，就要让他“训练”，让他学会。 4.数据集的应用，我们学会说话，学会认识物体，目的就是为了应用，学会说话，我们可以交流，认识自行车，是我们能够方便交通……数据集也一样，训练好的数据集的目的就是为了应用，或者说，我们训练数据集是因为我们需要应用这个数据集，例如，我们需要检测人流量，首先我们需要识别人，当然现在就有很多人体识别的算法，如果我们要采用数据集来识别，我们需要先制作一个数据集，然后在应用数据集完成我们需要的功能","categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"YOLO","slug":"深度学习/YOLO","permalink":"http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/YOLO/"},{"name":"树莓派","slug":"深度学习/YOLO/树莓派","permalink":"http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/YOLO/%E6%A0%91%E8%8E%93%E6%B4%BE/"}],"tags":[{"name":"YOLO","slug":"YOLO","permalink":"http://example.com/tags/YOLO/"},{"name":"目标识别检测","slug":"目标识别检测","permalink":"http://example.com/tags/%E7%9B%AE%E6%A0%87%E8%AF%86%E5%88%AB%E6%A3%80%E6%B5%8B/"},{"name":"训练数据集","slug":"训练数据集","permalink":"http://example.com/tags/%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E9%9B%86/"}],"author":"Ethan"},{"title":"戴面具的猫","slug":"test4","date":"2021-10-20T14:08:50.000Z","updated":"2021-10-22T03:37:29.132Z","comments":true,"path":"2021/10/20/test4/","link":"","permalink":"http://example.com/2021/10/20/test4/","excerpt":"","text":"图片","categories":[{"name":"图片","slug":"图片","permalink":"http://example.com/categories/%E5%9B%BE%E7%89%87/"}],"tags":[{"name":"蒙面猫猫","slug":"蒙面猫猫","permalink":"http://example.com/tags/%E8%92%99%E9%9D%A2%E7%8C%AB%E7%8C%AB/"},{"name":"吴彦祖","slug":"吴彦祖","permalink":"http://example.com/tags/%E5%90%B4%E5%BD%A6%E7%A5%96/"},{"name":"胖橘","slug":"胖橘","permalink":"http://example.com/tags/%E8%83%96%E6%A9%98/"},{"name":"HYUKOH","slug":"HYUKOH","permalink":"http://example.com/tags/HYUKOH/"}],"author":"Ethan"}],"categories":[{"name":"深度学习","slug":"深度学习","permalink":"http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"},{"name":"练习","slug":"深度学习/练习","permalink":"http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%BB%83%E4%B9%A0/"},{"name":"炼丹笔记","slug":"深度学习/炼丹笔记","permalink":"http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%82%BC%E4%B8%B9%E7%AC%94%E8%AE%B0/"},{"name":"极本穷源","slug":"极本穷源","permalink":"http://example.com/categories/%E6%9E%81%E6%9C%AC%E7%A9%B7%E6%BA%90/"},{"name":"图片","slug":"图片","permalink":"http://example.com/categories/%E5%9B%BE%E7%89%87/"},{"name":"搭建个人博客","slug":"搭建个人博客","permalink":"http://example.com/categories/%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"},{"name":"单片机","slug":"单片机","permalink":"http://example.com/categories/%E5%8D%95%E7%89%87%E6%9C%BA/"},{"name":"无人机","slug":"无人机","permalink":"http://example.com/categories/%E6%97%A0%E4%BA%BA%E6%9C%BA/"},{"name":"YOLO","slug":"深度学习/YOLO","permalink":"http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/YOLO/"},{"name":"Nvidia","slug":"深度学习/YOLO/Nvidia","permalink":"http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/YOLO/Nvidia/"},{"name":"计算机网络","slug":"计算机网络","permalink":"http://example.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"Ubuntu","slug":"深度学习/YOLO/Ubuntu","permalink":"http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/YOLO/Ubuntu/"},{"name":"windos","slug":"深度学习/YOLO/windos","permalink":"http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/YOLO/windos/"},{"name":"树莓派","slug":"深度学习/YOLO/树莓派","permalink":"http://example.com/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/YOLO/%E6%A0%91%E8%8E%93%E6%B4%BE/"}],"tags":[{"name":"前向传播函数","slug":"前向传播函数","permalink":"http://example.com/tags/%E5%89%8D%E5%90%91%E4%BC%A0%E6%92%AD%E5%87%BD%E6%95%B0/"},{"name":"forward","slug":"forward","permalink":"http://example.com/tags/forward/"},{"name":"实例","slug":"实例","permalink":"http://example.com/tags/%E5%AE%9E%E4%BE%8B/"},{"name":"类","slug":"类","permalink":"http://example.com/tags/%E7%B1%BB/"},{"name":"训练集","slug":"训练集","permalink":"http://example.com/tags/%E8%AE%AD%E7%BB%83%E9%9B%86/"},{"name":"测试集","slug":"测试集","permalink":"http://example.com/tags/%E6%B5%8B%E8%AF%95%E9%9B%86/"},{"name":"验证集","slug":"验证集","permalink":"http://example.com/tags/%E9%AA%8C%E8%AF%81%E9%9B%86/"},{"name":"卷积","slug":"卷积","permalink":"http://example.com/tags/%E5%8D%B7%E7%A7%AF/"},{"name":"池化","slug":"池化","permalink":"http://example.com/tags/%E6%B1%A0%E5%8C%96/"},{"name":"损失函数","slug":"损失函数","permalink":"http://example.com/tags/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/"},{"name":"yolov4-tiny","slug":"yolov4-tiny","permalink":"http://example.com/tags/yolov4-tiny/"},{"name":"cfg文件解读","slug":"cfg文件解读","permalink":"http://example.com/tags/cfg%E6%96%87%E4%BB%B6%E8%A7%A3%E8%AF%BB/"},{"name":"网络模型构建","slug":"网络模型构建","permalink":"http://example.com/tags/%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E6%9E%84%E5%BB%BA/"},{"name":"kmeans","slug":"kmeans","permalink":"http://example.com/tags/kmeans/"},{"name":"bounding boxs","slug":"bounding-boxs","permalink":"http://example.com/tags/bounding-boxs/"},{"name":"anchor boxes","slug":"anchor-boxes","permalink":"http://example.com/tags/anchor-boxes/"},{"name":"onnx","slug":"onnx","permalink":"http://example.com/tags/onnx/"},{"name":"yolo","slug":"yolo","permalink":"http://example.com/tags/yolo/"},{"name":"tensorrt","slug":"tensorrt","permalink":"http://example.com/tags/tensorrt/"},{"name":"飞桨","slug":"飞桨","permalink":"http://example.com/tags/%E9%A3%9E%E6%A1%A8/"},{"name":"Yolo-faster","slug":"Yolo-faster","permalink":"http://example.com/tags/Yolo-faster/"},{"name":"新冠","slug":"新冠","permalink":"http://example.com/tags/%E6%96%B0%E5%86%A0/"},{"name":"封城","slug":"封城","permalink":"http://example.com/tags/%E5%B0%81%E5%9F%8E/"},{"name":"mAP","slug":"mAP","permalink":"http://example.com/tags/mAP/"},{"name":"yolov3","slug":"yolov3","permalink":"http://example.com/tags/yolov3/"},{"name":"网络结构","slug":"网络结构","permalink":"http://example.com/tags/%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84/"},{"name":"AI炼丹","slug":"AI炼丹","permalink":"http://example.com/tags/AI%E7%82%BC%E4%B8%B9/"},{"name":"神经网络","slug":"神经网络","permalink":"http://example.com/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"},{"name":"沙滩企鹅","slug":"沙滩企鹅","permalink":"http://example.com/tags/%E6%B2%99%E6%BB%A9%E4%BC%81%E9%B9%85/"},{"name":"PicGo","slug":"PicGo","permalink":"http://example.com/tags/PicGo/"},{"name":"gitee图床","slug":"gitee图床","permalink":"http://example.com/tags/gitee%E5%9B%BE%E5%BA%8A/"},{"name":"Typora","slug":"Typora","permalink":"http://example.com/tags/Typora/"},{"name":"OSA","slug":"OSA","permalink":"http://example.com/tags/OSA/"},{"name":"生物雷达","slug":"生物雷达","permalink":"http://example.com/tags/%E7%94%9F%E7%89%A9%E9%9B%B7%E8%BE%BE/"},{"name":"呼吸暂停","slug":"呼吸暂停","permalink":"http://example.com/tags/%E5%91%BC%E5%90%B8%E6%9A%82%E5%81%9C/"},{"name":"薄膜式压力传感器","slug":"薄膜式压力传感器","permalink":"http://example.com/tags/%E8%96%84%E8%86%9C%E5%BC%8F%E5%8E%8B%E5%8A%9B%E4%BC%A0%E6%84%9F%E5%99%A8/"},{"name":"LoRa","slug":"LoRa","permalink":"http://example.com/tags/LoRa/"},{"name":"pixhawk2.4.8","slug":"pixhawk2-4-8","permalink":"http://example.com/tags/pixhawk2-4-8/"},{"name":"APM","slug":"APM","permalink":"http://example.com/tags/APM/"},{"name":"PX4","slug":"PX4","permalink":"http://example.com/tags/PX4/"},{"name":"电调","slug":"电调","permalink":"http://example.com/tags/%E7%94%B5%E8%B0%83/"},{"name":"DIY无人机","slug":"DIY无人机","permalink":"http://example.com/tags/DIY%E6%97%A0%E4%BA%BA%E6%9C%BA/"},{"name":"STM32","slug":"STM32","permalink":"http://example.com/tags/STM32/"},{"name":"NB-iot","slug":"NB-iot","permalink":"http://example.com/tags/NB-iot/"},{"name":"智能路灯","slug":"智能路灯","permalink":"http://example.com/tags/%E6%99%BA%E8%83%BD%E8%B7%AF%E7%81%AF/"},{"name":"硬件看门狗","slug":"硬件看门狗","permalink":"http://example.com/tags/%E7%A1%AC%E4%BB%B6%E7%9C%8B%E9%97%A8%E7%8B%97/"},{"name":"MOTT协议","slug":"MOTT协议","permalink":"http://example.com/tags/MOTT%E5%8D%8F%E8%AE%AE/"},{"name":"hexo","slug":"hexo","permalink":"http://example.com/tags/hexo/"},{"name":"端口占用","slug":"端口占用","permalink":"http://example.com/tags/%E7%AB%AF%E5%8F%A3%E5%8D%A0%E7%94%A8/"},{"name":"YOLO","slug":"YOLO","permalink":"http://example.com/tags/YOLO/"},{"name":"实时目标识别检测","slug":"实时目标识别检测","permalink":"http://example.com/tags/%E5%AE%9E%E6%97%B6%E7%9B%AE%E6%A0%87%E8%AF%86%E5%88%AB%E6%A3%80%E6%B5%8B/"},{"name":"jetson nano","slug":"jetson-nano","permalink":"http://example.com/tags/jetson-nano/"},{"name":"tensorRT","slug":"tensorRT","permalink":"http://example.com/tags/tensorRT/"},{"name":"Fluid","slug":"Fluid","permalink":"http://example.com/tags/Fluid/"},{"name":"gitalk","slug":"gitalk","permalink":"http://example.com/tags/gitalk/"},{"name":"古月居","slug":"古月居","permalink":"http://example.com/tags/%E5%8F%A4%E6%9C%88%E5%B1%85/"},{"name":"机器人","slug":"机器人","permalink":"http://example.com/tags/%E6%9C%BA%E5%99%A8%E4%BA%BA/"},{"name":"ROS基础","slug":"ROS基础","permalink":"http://example.com/tags/ROS%E5%9F%BA%E7%A1%80/"},{"name":"ROS节点","slug":"ROS节点","permalink":"http://example.com/tags/ROS%E8%8A%82%E7%82%B9/"},{"name":"协议栈","slug":"协议栈","permalink":"http://example.com/tags/%E5%8D%8F%E8%AE%AE%E6%A0%88/"},{"name":"TCP/IP协议栈","slug":"TCP-IP协议栈","permalink":"http://example.com/tags/TCP-IP%E5%8D%8F%E8%AE%AE%E6%A0%88/"},{"name":"OSI模型","slug":"OSI模型","permalink":"http://example.com/tags/OSI%E6%A8%A1%E5%9E%8B/"},{"name":"TCP/IP模型","slug":"TCP-IP模型","permalink":"http://example.com/tags/TCP-IP%E6%A8%A1%E5%9E%8B/"},{"name":"目标识别检测","slug":"目标识别检测","permalink":"http://example.com/tags/%E7%9B%AE%E6%A0%87%E8%AF%86%E5%88%AB%E6%A3%80%E6%B5%8B/"},{"name":"训练数据集","slug":"训练数据集","permalink":"http://example.com/tags/%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E9%9B%86/"},{"name":"连接","slug":"连接","permalink":"http://example.com/tags/%E8%BF%9E%E6%8E%A5/"},{"name":"上下采样","slug":"上下采样","permalink":"http://example.com/tags/%E4%B8%8A%E4%B8%8B%E9%87%87%E6%A0%B7/"},{"name":"markdown","slug":"markdown","permalink":"http://example.com/tags/markdown/"},{"name":"蒙面猫猫","slug":"蒙面猫猫","permalink":"http://example.com/tags/%E8%92%99%E9%9D%A2%E7%8C%AB%E7%8C%AB/"},{"name":"吴彦祖","slug":"吴彦祖","permalink":"http://example.com/tags/%E5%90%B4%E5%BD%A6%E7%A5%96/"},{"name":"胖橘","slug":"胖橘","permalink":"http://example.com/tags/%E8%83%96%E6%A9%98/"},{"name":"HYUKOH","slug":"HYUKOH","permalink":"http://example.com/tags/HYUKOH/"}]}